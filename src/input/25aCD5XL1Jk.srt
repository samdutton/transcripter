1
00:00:00,000 --> 00:00:03,444
[MUSIC PLAYING]

2
00:00:03,444 --> 00:00:07,186


3
00:00:07,186 --> 00:00:08,310
PHIL WALTON: Hey, everyone.

4
00:00:08,310 --> 00:00:09,140
My name is Philip Walton.

5
00:00:09,140 --> 00:00:11,681
I'm an engineer on the Chrome
team working on web performance

6
00:00:11,681 --> 00:00:13,310
and Service Worker tooling.

7
00:00:13,310 --> 00:00:14,518
EWA GASPEROWICZ: And I'm Ewa.

8
00:00:14,518 --> 00:00:16,360
I'm also an engineer
on the Chrome team.

9
00:00:16,360 --> 00:00:19,820
Today we're going to talk about
Service Worker from the speed

10
00:00:19,820 --> 00:00:22,130
and resilience perspective.

11
00:00:22,130 --> 00:00:24,860
We'll look into how our
decisions regarding Service

12
00:00:24,860 --> 00:00:27,470
Worker implementation
can influence,

13
00:00:27,470 --> 00:00:31,130
both positively and negatively,
our site's performance.

14
00:00:31,130 --> 00:00:32,930
And we hope that by
the end of this talk,

15
00:00:32,930 --> 00:00:35,150
you'll have a really
good understanding

16
00:00:35,150 --> 00:00:38,690
of all the trade-offs involved
in using this more and more

17
00:00:38,690 --> 00:00:40,185
mainstream technology.

18
00:00:40,185 --> 00:00:41,810
PHIL WALTON: So Ewa,
I noticed you said

19
00:00:41,810 --> 00:00:43,060
Service Worker was mainstream.

20
00:00:43,060 --> 00:00:44,139
What makes you say that?

21
00:00:44,139 --> 00:00:45,680
EWA GASPEROWICZ:
Well, Service Worker

22
00:00:45,680 --> 00:00:48,380
is now supported in all
modern browsers, which

23
00:00:48,380 --> 00:00:50,630
means you can move
from treating this

24
00:00:50,630 --> 00:00:53,510
as a pure progressive
enhancement

25
00:00:53,510 --> 00:00:57,050
and treat it as a core part
of your site's architecture.

26
00:00:57,050 --> 00:00:59,390
Service Worker can do many
things, but in this talk

27
00:00:59,390 --> 00:01:03,960
we'll focus especially on
its caching capabilities.

28
00:01:03,960 --> 00:01:06,900
Often when we think about
Service Worker and caching,

29
00:01:06,900 --> 00:01:10,830
we usually associate it with
providing offline support.

30
00:01:10,830 --> 00:01:13,920
After all, one of the main
achievements of Service Worker

31
00:01:13,920 --> 00:01:17,730
was that we finally could get
rid of the offline downosaur

32
00:01:17,730 --> 00:01:22,170
and send him to the
well-deserved retirement.

33
00:01:22,170 --> 00:01:25,380
But apart from
that, Service Worker

34
00:01:25,380 --> 00:01:28,110
can also be a great
tool for improving

35
00:01:28,110 --> 00:01:31,170
the performance of
your online site,

36
00:01:31,170 --> 00:01:33,630
especially for your
returning users.

37
00:01:33,630 --> 00:01:36,600
When used right, it can give
you a serious boost in terms

38
00:01:36,600 --> 00:01:38,997
of speed on the repeated visit.

39
00:01:38,997 --> 00:01:40,080
PHIL WALTON: That's right.

40
00:01:40,080 --> 00:01:41,913
And on the other hand,
when used incorrectly

41
00:01:41,913 --> 00:01:44,280
or without proper
analysis, it can actually

42
00:01:44,280 --> 00:01:46,560
hamper a site's
performance, or even

43
00:01:46,560 --> 00:01:49,470
derail the whole
experience altogether.

44
00:01:49,470 --> 00:01:51,300
So as developers,
it's critical that we

45
00:01:51,300 --> 00:01:53,070
understand how
Service Worker affects

46
00:01:53,070 --> 00:01:54,510
the performance of our site.

47
00:01:54,510 --> 00:01:57,211
As with any technology, there
are both costs and benefits.

48
00:01:57,211 --> 00:01:58,710
And we want to
maximize the benefits

49
00:01:58,710 --> 00:02:00,939
while minimizing the costs.

50
00:02:00,939 --> 00:02:02,730
EWA GASPEROWICZ: Well,
using Service Worker

51
00:02:02,730 --> 00:02:06,040
brings a lot of benefits
in terms of performance.

52
00:02:06,040 --> 00:02:09,750
In many cases it allows you to
overcome the network latency

53
00:02:09,750 --> 00:02:10,350
entirely.

54
00:02:10,350 --> 00:02:12,270
For example, if you
cache your entire app,

55
00:02:12,270 --> 00:02:16,100
you don't need to go
to the network anymore.

56
00:02:16,100 --> 00:02:18,820
Also, if you have
some cached content,

57
00:02:18,820 --> 00:02:20,680
you can show it
immediately, even

58
00:02:20,680 --> 00:02:24,220
if a bit stale, and look for
the updates in the background

59
00:02:24,220 --> 00:02:25,030
at the same time.

60
00:02:25,030 --> 00:02:27,740


61
00:02:27,740 --> 00:02:31,590
It can also make your average
requests smaller on average.

62
00:02:31,590 --> 00:02:33,530
For example, in
the app show model

63
00:02:33,530 --> 00:02:36,650
where you're fetching just
partial part of your page

64
00:02:36,650 --> 00:02:40,590
rather than the
full HTML each time.

65
00:02:40,590 --> 00:02:43,290
Finally, there are some
more subtle benefits.

66
00:02:43,290 --> 00:02:45,210
For example, we know
that JavaScripts

67
00:02:45,210 --> 00:02:49,750
need to be parsed, compiled, and
executed before it can be used.

68
00:02:49,750 --> 00:02:51,130
This can take time.

69
00:02:51,130 --> 00:02:54,660
So engines like V8
use some heuristics

70
00:02:54,660 --> 00:02:56,990
to see if they can
actually store the bytecode

71
00:02:56,990 --> 00:02:59,940
from these phases to be
used on repeated visits

72
00:02:59,940 --> 00:03:02,140
to avoid this cost.

73
00:03:02,140 --> 00:03:05,010
Now in Service Worker, the
chances of a repeated visit

74
00:03:05,010 --> 00:03:06,220
are pretty high.

75
00:03:06,220 --> 00:03:09,120
So it can opt into
that optimization

76
00:03:09,120 --> 00:03:11,160
automatically for you.

77
00:03:11,160 --> 00:03:14,470
This means that it stores
the script as bytecode

78
00:03:14,470 --> 00:03:19,020
by default, making the
repeated visits faster.

79
00:03:19,020 --> 00:03:21,480
All these are really
good performance reasons

80
00:03:21,480 --> 00:03:24,160
to implement Service
Worker on your page.

81
00:03:24,160 --> 00:03:25,842
But it's not for free.

82
00:03:25,842 --> 00:03:27,300
Phil, what are the
costs of running

83
00:03:27,300 --> 00:03:28,990
Service Worker on your page?

84
00:03:28,990 --> 00:03:31,350
PHIL WALTON: Yeah, so the
first and arguably most often

85
00:03:31,350 --> 00:03:33,079
overlooked cost
of Service Worker

86
00:03:33,079 --> 00:03:35,370
is that it can take time for
the Service Worker process

87
00:03:35,370 --> 00:03:37,681
to start up if it's
not already running.

88
00:03:37,681 --> 00:03:39,180
And this can happen
if a user hasn't

89
00:03:39,180 --> 00:03:41,820
visited your site in a while.

90
00:03:41,820 --> 00:03:43,440
Let me show you what I mean.

91
00:03:43,440 --> 00:03:45,570
Consider a basic
network first strategy

92
00:03:45,570 --> 00:03:48,030
in which the service worker
just forwards the request

93
00:03:48,030 --> 00:03:49,710
from the web app
onto the network

94
00:03:49,710 --> 00:03:51,900
and doesn't touch
the cache at all.

95
00:03:51,900 --> 00:03:54,240
Since this web app is
running a service worker,

96
00:03:54,240 --> 00:03:56,940
every request then has to go
through that service worker,

97
00:03:56,940 --> 00:03:59,190
and if the service worker
process isn't currently

98
00:03:59,190 --> 00:04:02,250
running, the web app has to wait
for the browser to spin it up

99
00:04:02,250 --> 00:04:04,927
before it can make any request.

100
00:04:04,927 --> 00:04:06,510
So let's take a look
at the total time

101
00:04:06,510 --> 00:04:09,750
it takes to make a request
in various scenarios.

102
00:04:09,750 --> 00:04:12,360
In the case where the web app
isn't using Service Worker,

103
00:04:12,360 --> 00:04:15,420
the total time is just the
total of network latency.

104
00:04:15,420 --> 00:04:17,910
In the case where the web
app is using Service Worker

105
00:04:17,910 --> 00:04:20,321
and that service worker
is already running,

106
00:04:20,321 --> 00:04:21,779
there is a little
bit of extra cost

107
00:04:21,779 --> 00:04:23,520
because it has to go
through the service worker--

108
00:04:23,520 --> 00:04:25,080
the request has to go
through the service worker--

109
00:04:25,080 --> 00:04:26,900
but that cost isn't
usually too high.

110
00:04:26,900 --> 00:04:29,400
However, in the case where the
service worker is not running

111
00:04:29,400 --> 00:04:31,470
and needs to boot
up, that startup time

112
00:04:31,470 --> 00:04:33,907
can really delay the response.

113
00:04:33,907 --> 00:04:35,490
EWA GASPEROWICZ: So
in cases like this

114
00:04:35,490 --> 00:04:37,156
where the service
worker is actually not

115
00:04:37,156 --> 00:04:39,780
running on the page,
how long does it usually

116
00:04:39,780 --> 00:04:40,447
take to boot up?

117
00:04:40,447 --> 00:04:42,071
PHIL WALTON: So that's
a good question.

118
00:04:42,071 --> 00:04:44,984
And the honest answer is it
depends on the user's device,

119
00:04:44,984 --> 00:04:46,650
but fortunately there
is an easy way you

120
00:04:46,650 --> 00:04:49,000
can measure this cost yourself.

121
00:04:49,000 --> 00:04:50,970
So this code here uses
the performance timeline

122
00:04:50,970 --> 00:04:53,132
to get performance data
for a particular URL.

123
00:04:53,132 --> 00:04:55,590
If the request for the URL went
through the service worker,

124
00:04:55,590 --> 00:04:57,900
then the worker start property
on the performance entry

125
00:04:57,900 --> 00:04:59,775
will mark the moment
right before the service

126
00:04:59,775 --> 00:05:00,930
worker was run.

127
00:05:00,930 --> 00:05:02,430
And the request
start property will

128
00:05:02,430 --> 00:05:04,230
mark the moment the
service worker received

129
00:05:04,230 --> 00:05:05,134
the fetch event.

130
00:05:05,134 --> 00:05:07,050
So the difference between
these two timestamps

131
00:05:07,050 --> 00:05:10,351
is the total time it took
for the worker to start up.

132
00:05:10,351 --> 00:05:12,600
And if the service worker
process was already running,

133
00:05:12,600 --> 00:05:15,299
this time will be usually
zero or close to zero.

134
00:05:15,299 --> 00:05:17,340
And so I actually measure
service worker start up

135
00:05:17,340 --> 00:05:19,950
time on my website,
philipwalton.com, and here's

136
00:05:19,950 --> 00:05:22,105
what I found when
looking at my own data.

137
00:05:22,105 --> 00:05:24,480
When users visits my site for
the first time-- or, sorry,

138
00:05:24,480 --> 00:05:26,990
for the first time after
installing the service worker--

139
00:05:26,990 --> 00:05:29,870
it's already running only
about 25% of the time.

140
00:05:29,870 --> 00:05:32,850
That means 75% of the time the
service worker is not running

141
00:05:32,850 --> 00:05:34,980
and needs to take
some time to start up.

142
00:05:34,980 --> 00:05:38,010
For those cases, I found
that on desktop it's

143
00:05:38,010 --> 00:05:40,950
usually between 20 and 100
milliseconds to start up,

144
00:05:40,950 --> 00:05:44,010
but on mobile it can be more
like 100 to 500 milliseconds,

145
00:05:44,010 --> 00:05:46,170
and at the 95th
percentile, sometimes it's

146
00:05:46,170 --> 00:05:47,620
more than a second.

147
00:05:47,620 --> 00:05:49,950
So let me reiterate, these
are stats from my website.

148
00:05:49,950 --> 00:05:51,750
The numbers you see
might be different,

149
00:05:51,750 --> 00:05:53,880
but this should give
you a general idea

150
00:05:53,880 --> 00:05:56,011
of what's possible.

151
00:05:56,011 --> 00:05:58,510
Another cost of using Service
Worker is that the cache reads

152
00:05:58,510 --> 00:06:00,140
aren't always instant.

153
00:06:00,140 --> 00:06:01,930
And this affects
any caching strategy

154
00:06:01,930 --> 00:06:04,013
where the service worker
has to wait for the cache

155
00:06:04,013 --> 00:06:07,559
to either miss or error before
it can go to the network.

156
00:06:07,559 --> 00:06:09,350
We saw before that a
network first strategy

157
00:06:09,350 --> 00:06:12,157
can be slow when you're not
using Service Worker at all.

158
00:06:12,157 --> 00:06:14,240
But what about strategies
that use cache, or start

159
00:06:14,240 --> 00:06:15,519
with the cache, anyway?

160
00:06:15,519 --> 00:06:17,060
A cache first strategy
will initially

161
00:06:17,060 --> 00:06:20,060
look for a response in the
cache, and if one is found

162
00:06:20,060 --> 00:06:20,924
it'll be used.

163
00:06:20,924 --> 00:06:23,090
But if it's not found or
there's a timeout or error,

164
00:06:23,090 --> 00:06:25,799
like I mentioned, it will
fall back to the network.

165
00:06:25,799 --> 00:06:28,090
So here's how the performance
of cache first strategies

166
00:06:28,090 --> 00:06:30,450
break down in
different scenarios.

167
00:06:30,450 --> 00:06:31,910
The most common
case is going to be

168
00:06:31,910 --> 00:06:33,860
the one at the top,
which is very fast when

169
00:06:33,860 --> 00:06:35,980
there's a cache hit.

170
00:06:35,980 --> 00:06:37,840
But this is not the
only possibility.

171
00:06:37,840 --> 00:06:39,670
There could also
be a cache miss,

172
00:06:39,670 --> 00:06:42,617
there could be a slow cache,
you could have a timeout--

173
00:06:42,617 --> 00:06:44,200
remember, there's
also the possibility

174
00:06:44,200 --> 00:06:45,658
of the service
worker isn't running

175
00:06:45,658 --> 00:06:47,840
and so then that could
delay it as well.

176
00:06:47,840 --> 00:06:51,170
All of these bad cases could
happen at the same time.

177
00:06:51,170 --> 00:06:53,410
So while it's definitely
possible to have a cache

178
00:06:53,410 --> 00:06:56,080
first strategy that's faster
than not using a service

179
00:06:56,080 --> 00:06:58,420
worker, look at how
many of these examples

180
00:06:58,420 --> 00:06:59,299
end up being slower.

181
00:06:59,299 --> 00:07:00,340
EWA GASPEROWICZ: So Phil.

182
00:07:00,340 --> 00:07:04,300
I'm wondering how likely is it
that the slow cases actually

183
00:07:04,300 --> 00:07:05,110
occur.

184
00:07:05,110 --> 00:07:06,250
Is it measurable somehow?

185
00:07:06,250 --> 00:07:07,000
PHIL WALTON: Yeah.

186
00:07:07,000 --> 00:07:08,920
So this is also measurable.

187
00:07:08,920 --> 00:07:11,950
It's a little bit trickier than
the last example I was showing.

188
00:07:11,950 --> 00:07:15,700
So this, the same way, uses
the performance timeline,

189
00:07:15,700 --> 00:07:19,120
and you can look at the
entries transfer size property.

190
00:07:19,120 --> 00:07:20,737
If the transfer
size is zero, that

191
00:07:20,737 --> 00:07:22,570
means the request either
came from the cache

192
00:07:22,570 --> 00:07:23,952
or came from the service worker.

193
00:07:23,952 --> 00:07:26,410
For requests that you know are
being handled by the service

194
00:07:26,410 --> 00:07:28,660
worker because you set
up a route for that URL,

195
00:07:28,660 --> 00:07:30,784
you can look at the time
between the response start

196
00:07:30,784 --> 00:07:32,830
property and the
request start property

197
00:07:32,830 --> 00:07:35,530
and see the total strategy time.

198
00:07:35,530 --> 00:07:38,020
Of course, that doesn't tell
you if it was just handled

199
00:07:38,020 --> 00:07:40,900
by the cache, if it was handled
by cache and the network.

200
00:07:40,900 --> 00:07:44,890
If you need more granular
timing data into that stuff,

201
00:07:44,890 --> 00:07:46,690
then you have to add
these performance

202
00:07:46,690 --> 00:07:48,190
marks in your service
worker itself.

203
00:07:48,190 --> 00:07:50,410
You can use something
like performance.now.

204
00:07:50,410 --> 00:07:52,535
and then post message this
data back to the window.

205
00:07:52,535 --> 00:07:54,460
It's a bit clunky at the
moment, to be honest,

206
00:07:54,460 --> 00:07:57,880
but we have a new API proposal
for fetch event work timing

207
00:07:57,880 --> 00:07:59,800
that should make this
easier in the future.

208
00:07:59,800 --> 00:08:01,460
And it is a proposal right now.

209
00:08:01,460 --> 00:08:03,940
So if you want to offer
feedback on the design,

210
00:08:03,940 --> 00:08:07,000
go to this short link
here on the slide,

211
00:08:07,000 --> 00:08:10,771
and we love your feedback,
and you can chime in.

212
00:08:10,771 --> 00:08:12,520
So the last call that
we want to point out

213
00:08:12,520 --> 00:08:15,240
is that requests made from
within the service worker

214
00:08:15,240 --> 00:08:16,990
can sometimes compete
with higher priority

215
00:08:16,990 --> 00:08:19,280
requests on the window.

216
00:08:19,280 --> 00:08:22,196
And the cause of this is usually
overaggressive pre-caching

217
00:08:22,196 --> 00:08:24,070
or pre-caching before
the window has finished

218
00:08:24,070 --> 00:08:25,940
loading all of its resources.

219
00:08:25,940 --> 00:08:28,090
So for example, if you're
pre-caching literally

220
00:08:28,090 --> 00:08:30,730
every single asset
on your website,

221
00:08:30,730 --> 00:08:32,409
you could potentially
get to a situation

222
00:08:32,409 --> 00:08:34,030
where those pre-cache
requests get

223
00:08:34,030 --> 00:08:38,919
queued ahead of more important
requests that the user needs.

224
00:08:38,919 --> 00:08:40,470
So while APIs like
priority hints

225
00:08:40,470 --> 00:08:43,500
can solve this issue somewhat,
the recommended approach right

226
00:08:43,500 --> 00:08:46,350
now is just to wait to
register your service worker

227
00:08:46,350 --> 00:08:49,087
until after the load event.

228
00:08:49,087 --> 00:08:49,920
EWA GASPEROWICZ: OK.

229
00:08:49,920 --> 00:08:53,010
Thanks, Phil, for the thorough
walkthrough through the costs.

230
00:08:53,010 --> 00:08:56,550
So once we know all this and
we know how to measure it,

231
00:08:56,550 --> 00:09:00,450
how does this translate into
the design of Service Worker?

232
00:09:00,450 --> 00:09:03,870
Well, usually there are three
sources the service worker gets

233
00:09:03,870 --> 00:09:07,620
content from, either from
network, either from the cache,

234
00:09:07,620 --> 00:09:09,480
or it can also
generate it on the fly,

235
00:09:09,480 --> 00:09:12,930
for example, by using
some templating logic.

236
00:09:12,930 --> 00:09:15,240
When designing Service
Worker, your role

237
00:09:15,240 --> 00:09:18,690
is to find a combination
of these three sources

238
00:09:18,690 --> 00:09:20,790
that is the most
efficient for the use

239
00:09:20,790 --> 00:09:22,620
cases on your web pages.

240
00:09:22,620 --> 00:09:25,860
This is the serving
strategy of Service Worker.

241
00:09:25,860 --> 00:09:28,170
Of course, in order to use
anything from the cache,

242
00:09:28,170 --> 00:09:30,540
we need to populate it first
with the resources first.

243
00:09:30,540 --> 00:09:34,690
And this is the caching
strategy of Service Worker.

244
00:09:34,690 --> 00:09:38,140
Taking all these aspects into
account can be quite daunting,

245
00:09:38,140 --> 00:09:41,000
but fortunately there are
tools that make it easier.

246
00:09:41,000 --> 00:09:43,510
For example, Workbox
is a set of libraries

247
00:09:43,510 --> 00:09:45,460
that make it easy
to cache assets

248
00:09:45,460 --> 00:09:48,610
and take advantage of Service
Worker features and related

249
00:09:48,610 --> 00:09:50,200
APIs.

250
00:09:50,200 --> 00:09:53,770
In this talk we'll focus on
the general design principles

251
00:09:53,770 --> 00:09:56,870
that you can implement
yourself in Service Worker.

252
00:09:56,870 --> 00:10:00,130
But we will also call out
some of the Workbox features

253
00:10:00,130 --> 00:10:03,037
that can help you out in
some common scenarios.

254
00:10:03,037 --> 00:10:04,870
PHIL WALTON: OK, so
let's start with looking

255
00:10:04,870 --> 00:10:08,419
at the serving strategies for
Service Worker implementations.

256
00:10:08,419 --> 00:10:10,960
And given what we said about
the costs that can be associated

257
00:10:10,960 --> 00:10:13,314
with using Service Worker,
you're probably wondering,

258
00:10:13,314 --> 00:10:15,730
is it possible to avoid these
costs entirely and make sure

259
00:10:15,730 --> 00:10:18,250
that my site actually loads
faster than it would have

260
00:10:18,250 --> 00:10:21,130
without the service worker?

261
00:10:21,130 --> 00:10:23,390
So the first and arguably
most important step

262
00:10:23,390 --> 00:10:25,970
in building a fast site
with A Service worker

263
00:10:25,970 --> 00:10:28,070
is an understanding
of which requests

264
00:10:28,070 --> 00:10:29,900
are most important to optimize.

265
00:10:29,900 --> 00:10:31,850
So broadly speaking,
there are two types

266
00:10:31,850 --> 00:10:34,880
of requests, navigation
requests and resource requests.

267
00:10:34,880 --> 00:10:37,610
Navigation requests are
for your full HTML pages

268
00:10:37,610 --> 00:10:39,680
and resource requests
are for the assets

269
00:10:39,680 --> 00:10:43,790
like JavaScript, CSS, and
images that those pages then

270
00:10:43,790 --> 00:10:44,810
reference.

271
00:10:44,810 --> 00:10:47,300
So in my experience with
talking to other developers

272
00:10:47,300 --> 00:10:48,987
about Service Worker
implementations,

273
00:10:48,987 --> 00:10:50,570
I found that most
people are generally

274
00:10:50,570 --> 00:10:52,820
pretty good at responding
to resource requests

275
00:10:52,820 --> 00:10:55,310
from the cache,
but unfortunately I

276
00:10:55,310 --> 00:10:58,220
don't see a lot of people
responding to navigation

277
00:10:58,220 --> 00:10:59,751
requests from the cache.

278
00:10:59,751 --> 00:11:02,000
And that's really too bad,
because navigation requests

279
00:11:02,000 --> 00:11:05,730
are typically where the biggest
performance gains can be made.

280
00:11:05,730 --> 00:11:06,767
So here's why.

281
00:11:06,767 --> 00:11:08,600
The key difference
between resource requests

282
00:11:08,600 --> 00:11:12,050
and navigation requests is that
navigation requests are likely

283
00:11:12,050 --> 00:11:15,000
already being cached
by the browser.

284
00:11:15,000 --> 00:11:16,730
In addition, you
can already use APIs

285
00:11:16,730 --> 00:11:19,330
like link rel preload
to warm the HTTP

286
00:11:19,330 --> 00:11:21,080
cache for future requests.

287
00:11:21,080 --> 00:11:23,180
So if all your service
worker is doing

288
00:11:23,180 --> 00:11:25,430
is pre-caching static
resources, you're

289
00:11:25,430 --> 00:11:28,100
essentially just recreating
what the browser is already

290
00:11:28,100 --> 00:11:29,660
doing for you.

291
00:11:29,660 --> 00:11:31,500
Navigation requests,
on the other hand,

292
00:11:31,500 --> 00:11:32,750
are completely different.

293
00:11:32,750 --> 00:11:36,200
In general it's not recommended
to put caching headers on pages

294
00:11:36,200 --> 00:11:38,840
that you navigate to because,
obviously the content might

295
00:11:38,840 --> 00:11:41,240
change but the URL doesn't,
and so that can get you

296
00:11:41,240 --> 00:11:42,471
into trouble.

297
00:11:42,471 --> 00:11:43,970
Which means that
navigation requests

298
00:11:43,970 --> 00:11:46,910
don't benefit from the
HTTP cache in the same way

299
00:11:46,910 --> 00:11:48,500
that resource requests do.

300
00:11:48,500 --> 00:11:51,690
They also don't work with
APIs like link rel preload.

301
00:11:51,690 --> 00:11:53,690
And to top all that off,
navigation requests are

302
00:11:53,690 --> 00:11:56,630
typically the ones that
will encounter a service

303
00:11:56,630 --> 00:11:59,690
worker that's not running,
whereas resource requests,

304
00:11:59,690 --> 00:12:02,100
by the time the service worker
starts up the navigation

305
00:12:02,100 --> 00:12:04,980
requests, it's already running
and so those work just fine.

306
00:12:04,980 --> 00:12:06,074
So don't get me wrong.

307
00:12:06,074 --> 00:12:08,240
I'm not suggesting that you
ignore resource requests

308
00:12:08,240 --> 00:12:09,115
and don't cache them.

309
00:12:09,115 --> 00:12:11,962
You should cache them, because
that can give you more control

310
00:12:11,962 --> 00:12:13,670
and you can get the
bytecode optimization

311
00:12:13,670 --> 00:12:15,081
that Ewa mentioned.

312
00:12:15,081 --> 00:12:17,330
But what I am suggesting is
that if you want your site

313
00:12:17,330 --> 00:12:19,280
to be as fast as
possible you have

314
00:12:19,280 --> 00:12:21,560
to respond to navigation
requests from the cache

315
00:12:21,560 --> 00:12:23,580
as well.

316
00:12:23,580 --> 00:12:25,670
So here are three
practical and concrete ways

317
00:12:25,670 --> 00:12:27,740
you can speed up
navigation requests

318
00:12:27,740 --> 00:12:29,780
and avoid most of the
Service Worker costs

319
00:12:29,780 --> 00:12:31,580
that I mentioned earlier.

320
00:12:31,580 --> 00:12:34,670
First, as I just said,
respond to navigation requests

321
00:12:34,670 --> 00:12:35,750
from the cache.

322
00:12:35,750 --> 00:12:37,820
Even if you eventually
need to go to the network,

323
00:12:37,820 --> 00:12:39,195
you should respond
with something

324
00:12:39,195 --> 00:12:41,960
right away so the
user understands

325
00:12:41,960 --> 00:12:44,990
that it's happening, that
the request is working.

326
00:12:44,990 --> 00:12:47,060
A simple way to do
this with Workbox

327
00:12:47,060 --> 00:12:49,700
is to use either a cache first
strategy or a stale while

328
00:12:49,700 --> 00:12:51,140
revalidate strategy.

329
00:12:51,140 --> 00:12:52,850
Personally, I like
stale while revalidate

330
00:12:52,850 --> 00:12:53,960
because it gives
you an opportunity

331
00:12:53,960 --> 00:12:55,880
to check for updates
in the background,

332
00:12:55,880 --> 00:12:59,570
and then you can notify the
user if there's new content.

333
00:12:59,570 --> 00:13:01,760
In terms of performance,
as you can see,

334
00:13:01,760 --> 00:13:03,770
responding from the
cache is generally faster

335
00:13:03,770 --> 00:13:05,382
when not using a service worker.

336
00:13:05,382 --> 00:13:07,340
And that's even true in
cases where the service

337
00:13:07,340 --> 00:13:09,530
worker's asleep and needs
to start up, or in cases

338
00:13:09,530 --> 00:13:11,580
where the cache is slow.

339
00:13:11,580 --> 00:13:14,142
The only situation it's worse
is when there's a cache miss

340
00:13:14,142 --> 00:13:15,850
and you have to go to
the network anyway.

341
00:13:15,850 --> 00:13:18,160
But that's to be expected.

342
00:13:18,160 --> 00:13:20,560
So I know what many of you
here are probably thinking.

343
00:13:20,560 --> 00:13:25,120
There's absolutely no way that
I can respond to all navigation

344
00:13:25,120 --> 00:13:26,800
requests with cache content.

345
00:13:26,800 --> 00:13:28,300
I need my content
to be up to date.

346
00:13:28,300 --> 00:13:29,320
I need it to be fresh.

347
00:13:29,320 --> 00:13:30,028
And this is true.

348
00:13:30,028 --> 00:13:32,811
Many apps just simply cannot
provide value with stale

349
00:13:32,811 --> 00:13:33,310
content.

350
00:13:33,310 --> 00:13:35,390
They have to have fresh content.

351
00:13:35,390 --> 00:13:37,997
But just because you
need to fetch something

352
00:13:37,997 --> 00:13:39,580
from the network
doesn't mean that you

353
00:13:39,580 --> 00:13:42,640
need to fetch the entire
HTML page from the network.

354
00:13:42,640 --> 00:13:45,580
So my second tip is that when
the network content is truly

355
00:13:45,580 --> 00:13:49,420
required, fetch just the minimum
amount of content you need,

356
00:13:49,420 --> 00:13:52,060
and then combine that
content with other parts

357
00:13:52,060 --> 00:13:54,280
of the page, which should
already be in the cache.

358
00:13:54,280 --> 00:13:55,821
And even better is
if you can combine

359
00:13:55,821 --> 00:13:59,200
that content in the form of a
streaming response to the user.

360
00:13:59,200 --> 00:14:02,291
So let me show you an example
of what I mean by that.

361
00:14:02,291 --> 00:14:03,790
A lot of HTML pages
have a structure

362
00:14:03,790 --> 00:14:05,180
that looks something like this.

363
00:14:05,180 --> 00:14:08,110
You have kind of a head section,
a header, navigation, sidebar,

364
00:14:08,110 --> 00:14:10,030
footer, and lot of these
sections of the page

365
00:14:10,030 --> 00:14:13,660
repeat on every single
page throughout your site.

366
00:14:13,660 --> 00:14:16,360
The only thing that changes is
often a single content area,

367
00:14:16,360 --> 00:14:17,880
like you can see here.

368
00:14:17,880 --> 00:14:20,320
So in these types of
situations, clearly

369
00:14:20,320 --> 00:14:21,970
it's more efficient
to just fetch

370
00:14:21,970 --> 00:14:24,700
the stuff that's changed rather
than fetching all of that stuff

371
00:14:24,700 --> 00:14:25,454
every time.

372
00:14:25,454 --> 00:14:27,370
If you've ever built a
single page application

373
00:14:27,370 --> 00:14:29,495
you're probably kind of
familiar with this concept,

374
00:14:29,495 --> 00:14:32,300
though the streaming
part might be new to you.

375
00:14:32,300 --> 00:14:34,690
So here's a visualization
of the performance breakdown

376
00:14:34,690 --> 00:14:37,060
between traditional
network responses

377
00:14:37,060 --> 00:14:39,070
and a streaming response
that combines network

378
00:14:39,070 --> 00:14:41,720
content with cache content.

379
00:14:41,720 --> 00:14:44,710
So in the example on top,
since the network request

380
00:14:44,710 --> 00:14:47,806
is for the full HTML page, you
can see it takes a long time,

381
00:14:47,806 --> 00:14:49,180
and in the example
on the bottom,

382
00:14:49,180 --> 00:14:52,349
the network request is for
a smaller part of the HTML,

383
00:14:52,349 --> 00:14:54,140
and so there's less
data to be transferred.

384
00:14:54,140 --> 00:14:56,540
So it will typically
take less time.

385
00:14:56,540 --> 00:15:00,010
In addition, the cached content
can be fetched in parallel

386
00:15:00,010 --> 00:15:01,780
with the network
content so it doesn't

387
00:15:01,780 --> 00:15:05,170
add to the total time it
takes to make the request.

388
00:15:05,170 --> 00:15:08,470
And lastly-- and this is the
best part about streaming--

389
00:15:08,470 --> 00:15:09,940
since it is a
stream, we don't have

390
00:15:09,940 --> 00:15:12,370
to wait until all the
content is available to start

391
00:15:12,370 --> 00:15:14,110
sending something to the user.

392
00:15:14,110 --> 00:15:16,060
As soon as we have
the cached content

393
00:15:16,060 --> 00:15:18,130
from the start of the
page, the header section,

394
00:15:18,130 --> 00:15:19,847
we can send it to
the user right away.

395
00:15:19,847 --> 00:15:21,430
And then we can just
add to the stream

396
00:15:21,430 --> 00:15:24,380
once we get more network
content in later.

397
00:15:24,380 --> 00:15:27,790
So the overall experience is a
much faster time to first byte

398
00:15:27,790 --> 00:15:31,420
and then a faster
time overall as well

399
00:15:31,420 --> 00:15:33,130
If you've never used
streams before, you

400
00:15:33,130 --> 00:15:34,846
might be a little bit
scared of the idea.

401
00:15:34,846 --> 00:15:36,220
You might think
it's complicated.

402
00:15:36,220 --> 00:15:39,230
But actually, with
Workbox it's really easy.

403
00:15:39,230 --> 00:15:41,770
So what you do is you just
register a route like you would

404
00:15:41,770 --> 00:15:44,830
do with any Workbox
strategy, and then

405
00:15:44,830 --> 00:15:47,770
you invoke the strategy function
from the Workbox streams

406
00:15:47,770 --> 00:15:49,610
package.

407
00:15:49,610 --> 00:15:51,920
The strategy function takes
an array of other Workbox

408
00:15:51,920 --> 00:15:54,260
strategies and each
of these is expected

409
00:15:54,260 --> 00:15:56,870
to resolve to a response that
you then stitch together,

410
00:15:56,870 --> 00:16:00,170
and Workbox stitches it together
in the form of a stream.

411
00:16:00,170 --> 00:16:02,540
In this case, I'm
using cache first

412
00:16:02,540 --> 00:16:04,580
for the header part
and footer part,

413
00:16:04,580 --> 00:16:06,720
and I'm using network
first for the content

414
00:16:06,720 --> 00:16:09,075
so I can make sure
that it's fresh.

415
00:16:09,075 --> 00:16:09,950
And that's really it.

416
00:16:09,950 --> 00:16:11,990
Workbox takes care of
merging this concept together

417
00:16:11,990 --> 00:16:13,948
in a stream, and if the
browser doesn't support

418
00:16:13,948 --> 00:16:19,180
streams it automatically falls
back to a single text response.

419
00:16:19,180 --> 00:16:20,556
And because the
strategy requests

420
00:16:20,556 --> 00:16:22,388
less content from the
network and because it

421
00:16:22,388 --> 00:16:24,030
can read from the
cache in parallel,

422
00:16:24,030 --> 00:16:25,740
it's typically
quite a bit faster

423
00:16:25,740 --> 00:16:27,356
than the no service worker case.

424
00:16:27,356 --> 00:16:28,980
Of course, the actual
speed differences

425
00:16:28,980 --> 00:16:31,620
will depend on the size
of the content area

426
00:16:31,620 --> 00:16:33,439
relative to the
entire HTML page.

427
00:16:33,439 --> 00:16:34,980
And that will vary
from site to site.

428
00:16:34,980 --> 00:16:37,800
But in general, streaming cache
content with network content

429
00:16:37,800 --> 00:16:41,544
is one of the fastest ways to
respond to navigation requests.

430
00:16:41,544 --> 00:16:43,710
I say one of the fastest
ways because there actually

431
00:16:43,710 --> 00:16:48,160
is one more optimization that
we can get this even faster.

432
00:16:48,160 --> 00:16:49,770
So the last technique
for speeding up

433
00:16:49,770 --> 00:16:51,330
navigations that I
want to talk about

434
00:16:51,330 --> 00:16:54,120
is a new API called
Navigation Preload, which

435
00:16:54,120 --> 00:16:57,240
allows you to make the
navigation request in parallel

436
00:16:57,240 --> 00:16:59,250
with the service
worker starting up,

437
00:16:59,250 --> 00:17:01,740
essentially eliminating that
Service Worker boot up cost

438
00:17:01,740 --> 00:17:04,240
that I mentioned before.

439
00:17:04,240 --> 00:17:06,690
So by now you've probably
seen this chart many times.

440
00:17:06,690 --> 00:17:09,359
You understand that the
Service Worker boot up time can

441
00:17:09,359 --> 00:17:11,010
extend the navigation request.

442
00:17:11,010 --> 00:17:12,810
So with Navigation
Preload, what you do is

443
00:17:12,810 --> 00:17:15,920
you just do these
requests in parallel.

444
00:17:15,920 --> 00:17:19,369
And the way that this
works is the browser that

445
00:17:19,369 --> 00:17:23,910
sets this Service Worker
navigation preload header

446
00:17:23,910 --> 00:17:27,150
on the preload request, and
then that allows your server

447
00:17:27,150 --> 00:17:30,990
to respond to this request as
it would have had the request

448
00:17:30,990 --> 00:17:33,460
come directly from the
service worker itself.

449
00:17:33,460 --> 00:17:36,780
So for example, if you're using
the streaming partials strategy

450
00:17:36,780 --> 00:17:39,420
that I just discussed,
you could respond

451
00:17:39,420 --> 00:17:41,340
to the navigation
preload request the same

452
00:17:41,340 --> 00:17:45,120
as you would have if it had
come from the service worker.

453
00:17:45,120 --> 00:17:47,790
To use Navigation Preload,
it's relatively easy.

454
00:17:47,790 --> 00:17:49,540
All you have to
do is enable it--

455
00:17:49,540 --> 00:17:51,290
you probably want to
feature detect first,

456
00:17:51,290 --> 00:17:54,470
but then you enable it at any
point in the lifecycle, really,

457
00:17:54,470 --> 00:17:56,990
but it's often best to do
it in the activate event.

458
00:17:56,990 --> 00:17:58,880
And then once you've
enabled it, fetch events

459
00:17:58,880 --> 00:18:00,546
for navigation requests
will have access

460
00:18:00,546 --> 00:18:03,440
to a preload response
property which you can then

461
00:18:03,440 --> 00:18:06,419
use however you want.

462
00:18:06,419 --> 00:18:08,460
And looking at the
performance of this technique,

463
00:18:08,460 --> 00:18:11,940
you'll see how navigation
requests with Navigation

464
00:18:11,940 --> 00:18:18,630
Preload are even faster than the
already fast streaming example.

465
00:18:18,630 --> 00:18:21,157
And one last thing I want to
say about Navigation Preload

466
00:18:21,157 --> 00:18:22,740
is that you really
only want to use it

467
00:18:22,740 --> 00:18:27,240
in cases where you know you're
going to have to make a network

468
00:18:27,240 --> 00:18:29,170
request on navigations.

469
00:18:29,170 --> 00:18:31,500
If you can use just the cache
first strategy to respond

470
00:18:31,500 --> 00:18:33,850
to navigations, then
that ends up being faster

471
00:18:33,850 --> 00:18:36,420
and then you waste
the network request.

472
00:18:36,420 --> 00:18:37,920
So in general,
only use it if you

473
00:18:37,920 --> 00:18:40,860
know that you have to use
content from the network.

474
00:18:40,860 --> 00:18:43,579
So to summarize everything I've
said so far, even though there

475
00:18:43,579 --> 00:18:45,870
are definitely some costs
associated with using Service

476
00:18:45,870 --> 00:18:48,720
Worker, with the proper
serving strategy you can easily

477
00:18:48,720 --> 00:18:50,550
overcome these costs
and you can end up

478
00:18:50,550 --> 00:18:53,790
with a even faster loading
site than what you could have

479
00:18:53,790 --> 00:18:56,750
done without Service Worker.

480
00:18:56,750 --> 00:18:58,070
EWA GASPEROWICZ: OK.

481
00:18:58,070 --> 00:19:00,841
Now let's talk a bit about the
caching part of the Service

482
00:19:00,841 --> 00:19:01,340
Worker.

483
00:19:01,340 --> 00:19:04,050


484
00:19:04,050 --> 00:19:06,090
When we think about
cache management,

485
00:19:06,090 --> 00:19:08,340
we usually want to
achieve the following.

486
00:19:08,340 --> 00:19:11,310
We want to start the right
resources at the right time

487
00:19:11,310 --> 00:19:14,280
while controlling the overall
size of our application.

488
00:19:14,280 --> 00:19:16,530
We definitely want to
prevent quota overflow,

489
00:19:16,530 --> 00:19:19,860
because as developers, we do
have quite a bit of storage

490
00:19:19,860 --> 00:19:22,380
space on users' device,
but it's not unlimited,

491
00:19:22,380 --> 00:19:24,130
so we need to stick to that.

492
00:19:24,130 --> 00:19:25,920
And we also want
our resources to be

493
00:19:25,920 --> 00:19:27,840
as fresh as possible,
which means we

494
00:19:27,840 --> 00:19:31,140
need to have efficient updates.

495
00:19:31,140 --> 00:19:33,602
Now when it comes
to right resources,

496
00:19:33,602 --> 00:19:35,310
it's good to understand
what you actually

497
00:19:35,310 --> 00:19:38,340
want to put in the cache
in the first place.

498
00:19:38,340 --> 00:19:40,740
Resources are a little
bit like food, you know.

499
00:19:40,740 --> 00:19:43,500
There are the critical
ones, really important ones

500
00:19:43,500 --> 00:19:47,310
like some HTML core
scripts or basic styles.

501
00:19:47,310 --> 00:19:49,260
This should really get
the highest priority

502
00:19:49,260 --> 00:19:50,940
in terms of cache.

503
00:19:50,940 --> 00:19:54,240
Then there are non-critical
ones, for example,

504
00:19:54,240 --> 00:19:56,640
images that are not
visible straight away,

505
00:19:56,640 --> 00:20:00,430
or some big media files or
some additional widgets.

506
00:20:00,430 --> 00:20:03,460
We cache them on the
best effort basis.

507
00:20:03,460 --> 00:20:05,790
And finally,
there's trash, which

508
00:20:05,790 --> 00:20:09,390
means stuff that should not
be there in the first place.

509
00:20:09,390 --> 00:20:11,850
This is the bloat, the
unnecessary parts of your page,

510
00:20:11,850 --> 00:20:17,160
like unoptimized images, dead
code, unused script, and so on.

511
00:20:17,160 --> 00:20:19,890
Why do we have
trash in our pages?

512
00:20:19,890 --> 00:20:22,470
Well, because we're
humans and sometimes

513
00:20:22,470 --> 00:20:26,070
our projects are
simply not perfect.

514
00:20:26,070 --> 00:20:27,570
This moment, when
you're considering

515
00:20:27,570 --> 00:20:30,620
how to shape your caching
strategy for Service Worker,

516
00:20:30,620 --> 00:20:33,090
is a great time to
stop for a while,

517
00:20:33,090 --> 00:20:35,130
make an audit of
your page, and get

518
00:20:35,130 --> 00:20:38,550
rid of all that unnecessary
part before they end up

519
00:20:38,550 --> 00:20:42,070
clogging your user's device.

520
00:20:42,070 --> 00:20:44,040
So reviewing your
app and understanding

521
00:20:44,040 --> 00:20:47,370
which resources are critical
and which are not so critical

522
00:20:47,370 --> 00:20:50,360
will really help you later
in designing and updating

523
00:20:50,360 --> 00:20:53,110
your cache in an
efficient manner.

524
00:20:53,110 --> 00:20:55,550
Now what about timing?

525
00:20:55,550 --> 00:20:58,700
Usually we cache assets either
in the install event of Service

526
00:20:58,700 --> 00:20:59,240
Worker--

527
00:20:59,240 --> 00:21:02,510
that's usually pre-caching--
or later during the runtime

528
00:21:02,510 --> 00:21:04,230
of our application.

529
00:21:04,230 --> 00:21:05,780
Let's compare these two.

530
00:21:05,780 --> 00:21:08,570
So pre-caching is very
similar to installing

531
00:21:08,570 --> 00:21:11,180
a ready-made package
with your app.

532
00:21:11,180 --> 00:21:14,000
It's great for caching
the critical content,

533
00:21:14,000 --> 00:21:18,800
since we know it's most probably
going to be needed anyways.

534
00:21:18,800 --> 00:21:21,620
It's relatively easy to
implement and to manage

535
00:21:21,620 --> 00:21:24,560
and to update, because you can
just replace the whole package

536
00:21:24,560 --> 00:21:26,900
with the new
version when needed,

537
00:21:26,900 --> 00:21:29,060
and also because the
size of such package

538
00:21:29,060 --> 00:21:31,350
is known beforehand.

539
00:21:31,350 --> 00:21:33,180
On the other hand,
when using pre-caching,

540
00:21:33,180 --> 00:21:35,820
you need to make a lot
of arbitrary decisions

541
00:21:35,820 --> 00:21:39,030
about what your user is going
to need even before they start

542
00:21:39,030 --> 00:21:42,780
interacting with the page, which
might lead to the situation

543
00:21:42,780 --> 00:21:47,380
where you cache many more
resources than necessary.

544
00:21:47,380 --> 00:21:50,970
Also, as we mentioned before,
it can cause network congestion

545
00:21:50,970 --> 00:21:53,550
and compete with the
other network requests

546
00:21:53,550 --> 00:21:56,240
from the window.

547
00:21:56,240 --> 00:21:58,110
Runtime caching,
on the other hand,

548
00:21:58,110 --> 00:22:00,320
is really great for
non-critical assets

549
00:22:00,320 --> 00:22:03,530
because you can draw conclusions
from your user's behavior.

550
00:22:03,530 --> 00:22:06,350
For example cache only
images they already

551
00:22:06,350 --> 00:22:11,480
accessed, or cache
different parts of your app

552
00:22:11,480 --> 00:22:14,860
depending on the
user's entry point.

553
00:22:14,860 --> 00:22:16,870
On the other hand, the
problem with runtime

554
00:22:16,870 --> 00:22:19,870
is that you need to be
really careful about updates

555
00:22:19,870 --> 00:22:21,940
because assets might
end up in cache

556
00:22:21,940 --> 00:22:24,170
at different moments in time.

557
00:22:24,170 --> 00:22:26,440
For example, if resources
depend on each other,

558
00:22:26,440 --> 00:22:29,080
like you have a script
that depends on the markup

559
00:22:29,080 --> 00:22:31,690
and you end up caching
incompatible versions of them,

560
00:22:31,690 --> 00:22:32,630
you run into trouble.

561
00:22:32,630 --> 00:22:35,800
So you need to be very
careful about versioning.

562
00:22:35,800 --> 00:22:38,390
Also, important thing
is that in this case,

563
00:22:38,390 --> 00:22:40,200
the cache will grow over time.

564
00:22:40,200 --> 00:22:42,370
The size is not
known beforehand.

565
00:22:42,370 --> 00:22:45,280
So as the user
interacts with the app,

566
00:22:45,280 --> 00:22:48,350
the size will be different.

567
00:22:48,350 --> 00:22:49,580
Here's an example.

568
00:22:49,580 --> 00:22:52,780
This is a very simple
e-commerce app I built recently.

569
00:22:52,780 --> 00:22:56,470
If I cache pages in
this app at runtime

570
00:22:56,470 --> 00:22:58,390
and the homepage
is fully cached,

571
00:22:58,390 --> 00:23:02,200
it takes about 150 kilobytes
with all the images.

572
00:23:02,200 --> 00:23:04,600
But later when the user
navigates to a new category,

573
00:23:04,600 --> 00:23:08,230
like accessories page, it
gets added to the cache,

574
00:23:08,230 --> 00:23:11,500
and the overall size
grows to 300 kilobytes.

575
00:23:11,500 --> 00:23:12,490
And so on and so on.

576
00:23:12,490 --> 00:23:16,456
As the user interacts with my
app, the overall size grows.

577
00:23:16,456 --> 00:23:17,830
If the app is
really big it might

578
00:23:17,830 --> 00:23:21,010
be really hard to predict
ahead of time how much space it

579
00:23:21,010 --> 00:23:23,020
will take on users' device.

580
00:23:23,020 --> 00:23:26,920
This is why it's so important
to control the size of your app

581
00:23:26,920 --> 00:23:28,770
through the runtime.

582
00:23:28,770 --> 00:23:31,570
Phil, can we do it
programmatically somehow?

583
00:23:31,570 --> 00:23:33,220
PHIL WALTON: You can.

584
00:23:33,220 --> 00:23:37,030
If you ever need to check your
app's current storage usage,

585
00:23:37,030 --> 00:23:39,640
you can use the Storage
Manager API which

586
00:23:39,640 --> 00:23:43,480
has an estimate method that
returns, both the total quota

587
00:23:43,480 --> 00:23:46,824
as well as the current
amount that's being used.

588
00:23:46,824 --> 00:23:48,240
EWA GASPEROWICZ:
Well, it's really

589
00:23:48,240 --> 00:23:50,620
cool that we can
estimate that, because it

590
00:23:50,620 --> 00:23:53,410
allows us to proactively
control the app size

591
00:23:53,410 --> 00:23:55,680
and prevent quota overflow.

592
00:23:55,680 --> 00:23:59,170
Quota is limited and depends
both on users' device

593
00:23:59,170 --> 00:24:02,530
and also on the amount of
currently available space

594
00:24:02,530 --> 00:24:03,920
on the device.

595
00:24:03,920 --> 00:24:06,460
So you can't just throw
assets into the cache

596
00:24:06,460 --> 00:24:08,830
and assume it will
never fill up.

597
00:24:08,830 --> 00:24:11,680
You always need to have
a plan on how to remove

598
00:24:11,680 --> 00:24:13,589
old or unnecessary assets.

599
00:24:13,589 --> 00:24:15,130
After all, you don't
want a situation

600
00:24:15,130 --> 00:24:17,830
where you can't update
some critical script

601
00:24:17,830 --> 00:24:20,350
because your cache is
full of cat videos.

602
00:24:20,350 --> 00:24:23,500


603
00:24:23,500 --> 00:24:25,000
Here are some
things that can help

604
00:24:25,000 --> 00:24:27,160
you to stay below the quota.

605
00:24:27,160 --> 00:24:29,440
As we mentioned
before, you can store

606
00:24:29,440 --> 00:24:32,710
partials of your pages
instead of full HTML

607
00:24:32,710 --> 00:24:35,920
to avoid duplication
and save some space.

608
00:24:35,920 --> 00:24:38,740
You can also separate your
critical and non-critical

609
00:24:38,740 --> 00:24:41,920
assets into different
caches with different names,

610
00:24:41,920 --> 00:24:45,220
so that you can evict the
non-critical ones when needed

611
00:24:45,220 --> 00:24:48,150
without touching the rest.

612
00:24:48,150 --> 00:24:51,150
Finally, you can also
cache some resources

613
00:24:51,150 --> 00:24:54,210
only if there is plenty of
space, like conditionally.

614
00:24:54,210 --> 00:24:58,080
Or you can put size or maximum
number of entries constraints

615
00:24:58,080 --> 00:24:59,340
on your cache.

616
00:24:59,340 --> 00:25:01,620
I think this is something
Workbox can help us with.

617
00:25:01,620 --> 00:25:02,370
PHIL WALTON: Yeah.

618
00:25:02,370 --> 00:25:04,620
With Workbox you can
easily manage the rules

619
00:25:04,620 --> 00:25:07,890
for how and when cache entries
should expire with the Cache

620
00:25:07,890 --> 00:25:09,210
Expiration plugin.

621
00:25:09,210 --> 00:25:12,630
And you can use it with any
of the Workbox strategies.

622
00:25:12,630 --> 00:25:15,450
So you configure both a max
number of entries per cache

623
00:25:15,450 --> 00:25:17,770
or a max age for each entry.

624
00:25:17,770 --> 00:25:20,000
You can also
configure the plugin

625
00:25:20,000 --> 00:25:22,207
to automatically purge
all entries if there

626
00:25:22,207 --> 00:25:23,790
is any kind of quota
error or anything

627
00:25:23,790 --> 00:25:25,456
like that, which is
usually a good thing

628
00:25:25,456 --> 00:25:29,590
to do when you have a
non-critical asset cache.

629
00:25:29,590 --> 00:25:33,220
EWA GASPEROWICZ: OK, now a few
words about updating the cache.

630
00:25:33,220 --> 00:25:36,670
The simplest solution is what
I call the nuke approach, which

631
00:25:36,670 --> 00:25:39,640
means you clear all your caches
and start fresh every time

632
00:25:39,640 --> 00:25:41,440
your service worker updates.

633
00:25:41,440 --> 00:25:43,930
It's very easy to
implement, but it's not

634
00:25:43,930 --> 00:25:47,740
very efficient nor kind
to your user's data plans.

635
00:25:47,740 --> 00:25:50,990
So you should be more granular
about what you update and when.

636
00:25:50,990 --> 00:25:53,230
And if you want to
be more granular,

637
00:25:53,230 --> 00:25:55,450
you need to properly
tag your assets

638
00:25:55,450 --> 00:25:59,450
so that you know which ones
are compatible with each other.

639
00:25:59,450 --> 00:26:01,210
You can use the
content-based hashes

640
00:26:01,210 --> 00:26:03,790
in the file name of
the given resource,

641
00:26:03,790 --> 00:26:06,130
or provide revision
data on each asset

642
00:26:06,130 --> 00:26:09,550
so that you can manage it
in Service Worker later on.

643
00:26:09,550 --> 00:26:12,370
This process can be very
error-prone when done manually,

644
00:26:12,370 --> 00:26:14,770
so fortunately we have tools
to help with that as well.

645
00:26:14,770 --> 00:26:17,680
PHIL WALTON: Yeah, with the
Workbox pre-caching package,

646
00:26:17,680 --> 00:26:20,350
you don't have to
manually manage the update

647
00:26:20,350 --> 00:26:21,400
process yourself at all.

648
00:26:21,400 --> 00:26:24,970
It has an asset manifest
that maps file URLs

649
00:26:24,970 --> 00:26:27,280
to their revision
hashes, and that

650
00:26:27,280 --> 00:26:29,350
allows it to remove
old assets and fetch

651
00:26:29,350 --> 00:26:32,860
new ones without having to touch
any of the unchanged assets.

652
00:26:32,860 --> 00:26:35,880
It makes the upgrade
process really efficient.

653
00:26:35,880 --> 00:26:39,970
Workbox also has both Gulp and
Webpack plugins, as well as

654
00:26:39,970 --> 00:26:41,920
a CLI, so you can
easily generate

655
00:26:41,920 --> 00:26:45,210
this asset manifest yourself.

656
00:26:45,210 --> 00:26:48,000
EWA GASPEROWICZ: As you can see,
Workbox makes a lot of things

657
00:26:48,000 --> 00:26:50,370
easier for us as
developers so that we

658
00:26:50,370 --> 00:26:54,300
can focus on what matters
most, and that's the user.

659
00:26:54,300 --> 00:26:58,110
And users can really vary.

660
00:26:58,110 --> 00:26:59,610
They can be of
different background,

661
00:26:59,610 --> 00:27:02,550
they can use our app
at home or on the go,

662
00:27:02,550 --> 00:27:04,860
they can use more or
less advanced devices

663
00:27:04,860 --> 00:27:08,790
or have different access
to data and connectivity.

664
00:27:08,790 --> 00:27:11,820
There are some things
we can do to accommodate

665
00:27:11,820 --> 00:27:14,280
those differences.

666
00:27:14,280 --> 00:27:16,030
First of all, when
working on performance,

667
00:27:16,030 --> 00:27:18,190
never assume the
environment you work in

668
00:27:18,190 --> 00:27:20,559
is representative of
your whole user base.

669
00:27:20,559 --> 00:27:22,725
For example, you should
always throttle your network

670
00:27:22,725 --> 00:27:26,320
to 3G speed when testing to
get a more realistic feel

671
00:27:26,320 --> 00:27:29,060
for your performance.

672
00:27:29,060 --> 00:27:32,120
Secondly, keep in mind
those underpowered devices

673
00:27:32,120 --> 00:27:35,630
with little storage and really
control the size of your app.

674
00:27:35,630 --> 00:27:37,490
Remember that the
overall size of your app

675
00:27:37,490 --> 00:27:40,070
might grow over time if
you use runtime caching,

676
00:27:40,070 --> 00:27:42,750
and plan accordingly.

677
00:27:42,750 --> 00:27:44,630
Also, sometimes
there are actually

678
00:27:44,630 --> 00:27:47,060
explicit hints from
the user that you can

679
00:27:47,060 --> 00:27:49,280
use in your decision making.

680
00:27:49,280 --> 00:27:52,970
For example, you can refrain
from speculatively pre-caching

681
00:27:52,970 --> 00:27:57,080
future resources if the Data
Saver mode is turned on.

682
00:27:57,080 --> 00:27:59,690
When user enables this
feature in Chrome,

683
00:27:59,690 --> 00:28:02,310
the save data header is
being sent with each request.

684
00:28:02,310 --> 00:28:04,760
So you can detect
it and, for example,

685
00:28:04,760 --> 00:28:06,240
refrain from
aggressive pre-caching

686
00:28:06,240 --> 00:28:08,900
a lot of future assets.

687
00:28:08,900 --> 00:28:12,320
Similarly, you can use the
Network Information API

688
00:28:12,320 --> 00:28:15,500
effective type method to
differentiate your strategy

689
00:28:15,500 --> 00:28:19,580
based on the current network
condition of the user.

690
00:28:19,580 --> 00:28:22,340
Finally, you can also
consider scenarios

691
00:28:22,340 --> 00:28:25,590
where you give the user the full
control over the experience.

692
00:28:25,590 --> 00:28:28,640
For example, you provide
save for later button, where

693
00:28:28,640 --> 00:28:32,570
a user can explicitly opt in and
decide to get something stored

694
00:28:32,570 --> 00:28:34,980
for future use.

695
00:28:34,980 --> 00:28:36,450
Putting the user
first can really

696
00:28:36,450 --> 00:28:39,420
benefit the quality of
your app, especially

697
00:28:39,420 --> 00:28:42,754
in the long term
development horizon.

698
00:28:42,754 --> 00:28:44,170
PHIL WALTON: So
to wrap up, I know

699
00:28:44,170 --> 00:28:45,910
we've presented a
lot of content today,

700
00:28:45,910 --> 00:28:49,027
and we don't expect you
to remember everything.

701
00:28:49,027 --> 00:28:51,610
If you want to learn more about
Service Worker best practices,

702
00:28:51,610 --> 00:28:53,980
we've launched a new
section on web.dev

703
00:28:53,980 --> 00:28:56,696
with content dedicated to
building fast and resilient web

704
00:28:56,696 --> 00:28:58,070
applications with
Service Worker.

705
00:28:58,070 --> 00:29:00,170
So definitely check that out.

706
00:29:00,170 --> 00:29:03,100
Also, we've just released
a V4 beta of Workbox

707
00:29:03,100 --> 00:29:05,260
with lots of cool new
features, and we'd

708
00:29:05,260 --> 00:29:08,740
love your feedback on GitHub
before the public release.

709
00:29:08,740 --> 00:29:10,750
And finally, just
a few key points

710
00:29:10,750 --> 00:29:11,990
we want to leave you with.

711
00:29:11,990 --> 00:29:14,740
First, definitely have a plan.

712
00:29:14,740 --> 00:29:17,290
You can't just assume that
adding Service Worker to a site

713
00:29:17,290 --> 00:29:20,800
will magically make it faster,
because without an optimization

714
00:29:20,800 --> 00:29:23,200
plan it probably won't.

715
00:29:23,200 --> 00:29:26,110
Second, don't just
reinvent the HTTP cache

716
00:29:26,110 --> 00:29:28,690
inside of your service
worker, and don't just

717
00:29:28,690 --> 00:29:30,212
cache static resources.

718
00:29:30,212 --> 00:29:32,170
If that's all you're
doing, you're not actually

719
00:29:32,170 --> 00:29:33,940
optimizing your site
for Service Worker

720
00:29:33,940 --> 00:29:36,460
and you might even
be making it slower.

721
00:29:36,460 --> 00:29:38,770
Third, remember that
navigation requests are

722
00:29:38,770 --> 00:29:41,830
the most important
requests to optimize,

723
00:29:41,830 --> 00:29:45,310
and you should always try to
respond to them from the cache.

724
00:29:45,310 --> 00:29:48,280
Fourth, measure the
real user performance

725
00:29:48,280 --> 00:29:51,550
of your implementations and make
future performance decisions

726
00:29:51,550 --> 00:29:52,660
based on data.

727
00:29:52,660 --> 00:29:54,400
Don't just guess.

728
00:29:54,400 --> 00:29:56,470
Fifth, control the
size of your app

729
00:29:56,470 --> 00:29:59,450
and how much you store
on the user's device.

730
00:29:59,450 --> 00:30:02,050
And last but definitely not
least, respect the user,

731
00:30:02,050 --> 00:30:05,720
respect their data, and
respect their preferences.

732
00:30:05,720 --> 00:30:06,220
Thank you.

733
00:30:06,220 --> 00:30:08,595
If you have any questions,
feel free to find either of us

734
00:30:08,595 --> 00:30:12,130
afterwards, or hit us up on
Twitter and ask questions.

735
00:30:12,130 --> 00:30:13,060
That's it, yeah.

736
00:30:13,060 --> 00:30:14,184
EWA GASPEROWICZ: Thank you.

737
00:30:14,184 --> 00:30:16,920
[MUSIC PLAYING]

738
00:30:16,920 --> 00:30:24,135