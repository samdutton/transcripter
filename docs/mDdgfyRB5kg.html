<section>
<p><span data-start="0" data-end="3.816">[MUSIC PLAYING]</span> </p>
</section>

<section>
<p><span data-start="5.914" data-end="7.83"><span class="speaker">Shubhie Panicker</span>: My name is Shubhie Panicker.</span> <span data-start="7.83" data-end="10.782">I'm a software engineer working on the web platform in Chrome.</span> </p>
</section>

<section>
<p><span data-start="10.782" data-end="12.24"><span class="speaker">Jason Miller</span>: And I'm Jason Miller.</span> <span data-start="12.24" data-end="13.92">I'm a [INAUDIBLE] for Chrome.</span> </p>
</section>

<section>
<p><span data-start="13.92" data-end="15.378"><span class="speaker">Shubhie Panicker</span>: Our talk today is</span> <span data-start="15.378" data-end="18.96">about a key strategy for runtime performance of web apps,</span> <span data-start="18.96" data-end="22.23">and that is scheduling of JavaScript on the main thread,</span> <span data-start="22.23" data-end="26.25">as well as approaches for moving script off the main thread.</span> <span data-start="26.25" data-end="28.95">Jason and I have both been deep in this space</span> <span data-start="28.95" data-end="33.65">exploring gaps in APIs for what we are calling achieving</span> <span data-start="33.65" data-end="36.042">get responsiveness guarantees.</span> <span data-start="36.042" data-end="37.5">We're excited about the opportunity</span> <span data-start="37.5" data-end="40.2">here, both with existing primitives</span> <span data-start="40.2" data-end="43.19">as well as the new APIs we will show in our talk.</span> </p>
<p></p>
</section>

<section>
<p><span data-start="43.19" data-end="45.21"><span class="speaker">Jason Miller</span>: Right, so to get started,</span> <span data-start="45.21" data-end="47.56">let's illustrate this problem space using a demo.</span> <span data-start="47.56" data-end="50.43">So this is a simple application that searches through photos</span> <span data-start="50.43" data-end="51.87">as you type.</span> <span data-start="51.87" data-end="53.67">And you can see here with this JavaScript</span> <span data-start="53.67" data-end="55.59">controlled red spinner animation,</span> <span data-start="55.59" data-end="57.45">it's doing a fair amount of blocking work</span> <span data-start="57.45" data-end="58.83">on the main thread.</span> <span data-start="58.83" data-end="61.62">And while this is happening, the app can't respond to input.</span> <span data-start="61.62" data-end="63.99">So typing gets queued.</span> <span data-start="63.99" data-end="66.77">Looking closer, what we see if we pulled up the profiler</span> <span data-start="66.77" data-end="70.5">is something like this —  a sequence of long tasks</span> <span data-start="70.5" data-end="74.46">that block the main thread and cause that input queuing.</span> </p>
<p><span data-start="74.46" data-end="76.6">We can see this on a simplified view here.</span> <span data-start="76.6" data-end="79.05">So if we receive input and we start</span> <span data-start="79.05" data-end="81.47">doing some processing in response to that input — </span> <span data-start="81.47" data-end="84.33">say, searching photos rendering some list items — </span> <span data-start="84.33" data-end="86.4">we're skipping frames already.</span> <span data-start="86.4" data-end="89.1">But in addition to that, if we receive additional input</span> <span data-start="89.1" data-end="92.46">while that task is running, it will get queued,</span> <span data-start="92.46" data-end="97.05">and it only is able to execute once that has completed.</span> <span data-start="97.05" data-end="99.77">So this is data captured from real users</span> <span data-start="99.77" data-end="101.47">on real websites in the wild.</span> </p>
<p><span data-start="101.47" data-end="104.27">And it shows a breakdown of where Chrome was spending</span> <span data-start="104.27" data-end="106.481">its time while handling input.</span> <span data-start="106.481" data-end="108.23">So there's a lot of interesting data here,</span> <span data-start="108.23" data-end="110.105">but we don't really have time to get into it.</span> <span data-start="110.105" data-end="112.37">The main thing to look at is the amount of time</span> <span data-start="112.37" data-end="115.19">that we're spending in this V8.execute task.</span> <span data-start="115.19" data-end="117.02">That is Chrome running JavaScript</span> <span data-start="117.02" data-end="118.4">during touch handling.</span> <span data-start="118.4" data-end="120.2">And it's clearly the biggest contributor</span> <span data-start="120.2" data-end="123.68">to touch input latency, both on average and also in the worst</span> <span data-start="123.68" data-end="124.652">case.</span> </p>
</section>

<section>
<p><span data-start="124.652" data-end="126.86"><span class="speaker">Shubhie Panicker</span>: So a problem with our search as you</span> <span data-start="126.86" data-end="128.93">type example app is that there's just</span> <span data-start="128.93" data-end="131.89">a lot of different types of work happening here.</span> </p>
<p><span data-start="131.89" data-end="135.01">And all of these different work have what</span> <span data-start="135.01" data-end="137.48">we are calling rate deadlines.</span> <span data-start="137.48" data-end="140.24">So for example, the user is typing in that search box.</span> <span data-start="140.24" data-end="142.19">Their input has to be responsive.</span> <span data-start="142.19" data-end="144.17">There's ongoing animations on the page.</span> <span data-start="144.17" data-end="146.954">They have to render consistently and smoothly.</span> <span data-start="146.954" data-end="148.37">And then there's the heavy lifting</span> <span data-start="148.37" data-end="151.46">of fetching search results, post-processing, preparing,</span> <span data-start="151.46" data-end="153.98">rendering these search results in time</span> <span data-start="153.98" data-end="157.49">so that it's relevant to the user's typed in query.</span> <span data-start="157.49" data-end="160.04">The difficulty is that it's hard for apps</span> <span data-start="160.04" data-end="163.04">to balance these competing needs to reason</span> <span data-start="163.04" data-end="165.41">about all these different deadlines and keeping</span> <span data-start="165.41" data-end="168.256">everything meeting these timelines.</span> </p>
<p></p>
</section>

<section>
<p><span data-start="168.256" data-end="169.88"><span class="speaker">Jason Miller</span>: Right, so we have a bunch</span> <span data-start="169.88" data-end="171.14">of different types of work.</span> <span data-start="171.14" data-end="174.44">And each of those types of work has a different deadline.</span> <span data-start="174.44" data-end="176.81">And what we need to be able to work through this</span> <span data-start="176.81" data-end="178.119">is priorities.</span> </p>
</section>

<section>
<p><span data-start="178.119" data-end="179.66"><span class="speaker">Shubhie Panicker</span>: So there's a couple</span> <span data-start="179.66" data-end="182.42">high level approaches to try and achieve</span> <span data-start="182.42" data-end="183.68">responsiveness guarantees.</span> <span data-start="183.68" data-end="187.25">The first approach can just be doing less work.</span> <span data-start="187.25" data-end="190.94">And there are ways of doing this such as in an infinite feed,</span> <span data-start="190.94" data-end="193.25">you might only render what's visible.</span> <span data-start="193.25" data-end="195.68">We just saw a strategy with the virtual-scroller talk</span> <span data-start="195.68" data-end="196.79">right now.</span> <span data-start="196.79" data-end="199.37">Now this is not always possible.</span> <span data-start="199.37" data-end="202.79">Modern apps often just have a ton of work to do.</span> </p>
<p><span data-start="202.79" data-end="206.12">So a second strategy here is chunking up work</span> <span data-start="206.12" data-end="210.55">and prioritizing these chunks of work.</span> <span data-start="210.55" data-end="214.09">In practice, though, this is also very difficult.</span> <span data-start="214.09" data-end="217.39">It can be impractical to achieve this manually on your own</span> <span data-start="217.39" data-end="218.92">as an app developer.</span> <span data-start="218.92" data-end="222.13">And we think there's a real opportunity here for frameworks</span> <span data-start="222.13" data-end="224.38">to step in and help their users.</span> </p>
<p><span data-start="224.38" data-end="226.48">Frameworks are in a great position</span> <span data-start="226.48" data-end="230.86">to ensure chunking and prioritizing of work.</span> <span data-start="230.86" data-end="233.92">So stepping back a bit, what we need here</span> <span data-start="233.92" data-end="238.45">is some way to provide our chunks of work, our tasks,</span> <span data-start="238.45" data-end="242.41">to a system that can hold them, say, in a task queue,</span> <span data-start="242.41" data-end="244.69">and then the system can make good decisions</span> <span data-start="244.69" data-end="247.43">about when to take tasks out of the task queue</span> <span data-start="247.43" data-end="250.21">and execute them at an appropriate time based</span> <span data-start="250.21" data-end="252.52">on everything that's going on.</span> <span data-start="252.52" data-end="256.301">And this is the definition of a scheduler.</span> </p>
<p></p>
</section>

<section>
<p><span data-start="256.301" data-end="258.55"><span class="speaker">Jason Miller</span>: So Google Maps is a really great example</span> <span data-start="258.55" data-end="260.74">of an application that uses a scheduler to keep</span> <span data-start="260.74" data-end="262.75">its interactions smooth.</span> <span data-start="262.75" data-end="265.96">This app has to manage multiple different types of interactions</span> <span data-start="265.96" data-end="266.5">and events.</span> <span data-start="266.5" data-end="268.51">And these can all happen concurrently.</span> <span data-start="268.51" data-end="270.73">They do this by scheduling all work</span> <span data-start="270.73" data-end="273.31">and giving a much higher priority to input response</span> <span data-start="273.31" data-end="274.1">tasks.</span> <span data-start="274.1" data-end="275.03">We can see that here.</span> <span data-start="275.03" data-end="276.76">So let's say I'm panning the map.</span> <span data-start="276.76" data-end="278.92">And as I'm panning, additional tiles</span> <span data-start="278.92" data-end="281.35">are coming into the viewport and need to be loaded.</span> <span data-start="281.35" data-end="283.81">However, if I stop panning and I pull up</span> <span data-start="283.81" data-end="285.73">the drawer at the bottom, all of a sudden,</span> <span data-start="285.73" data-end="289.49">that is far and away the most high priority task to execute.</span> </p>
<p><span data-start="289.49" data-end="294.142">So those map tiles being loaded need to be de-prioritized.</span> </p>
</section>

<section>
<p><span data-start="294.142" data-end="296.35"><span class="speaker">Shubhie Panicker</span>: So a key aspect of a good scheduler</span> <span data-start="296.35" data-end="300.35">is its ability to execute work at the best time.</span> <span data-start="300.35" data-end="302.02">And this is an appropriate time based</span> <span data-start="302.02" data-end="304.66">on everything that's going on, various factors like,</span> <span data-start="304.66" data-end="307.39">what's the type of the task, what's important to the user</span> <span data-start="307.39" data-end="310.63">right now, what's the overall state of the application,</span> <span data-start="310.63" data-end="314.29">what's the internal state of the browser, et cetera.</span> <span data-start="314.29" data-end="317.11">So to understand this notion of best time,</span> <span data-start="317.11" data-end="321.22">we have to step down a level and look at the browser's rendering</span> <span data-start="321.22" data-end="322.36">pipeline.</span> </p>
<p><span data-start="322.36" data-end="325.36">The browser is periodically bumping frames, typically</span> <span data-start="325.36" data-end="329.74">every 16 milliseconds for a 60 frames per second display rate.</span> <span data-start="329.74" data-end="334.33">And each frame has a set of things that happen in sequence.</span> <span data-start="334.33" data-end="337.45">For instance, we have request animation frames followed</span> <span data-start="337.45" data-end="339.46">by style, layout, and paint.</span> <span data-start="339.46" data-end="342.25">In Chrome, input handlers are aligned right</span> <span data-start="342.25" data-end="344.84">before request animation frame callbacks.</span> <span data-start="344.84" data-end="348.55">So the point here is that there is limited time</span> <span data-start="348.55" data-end="353.11">to do the urgent work that needs to happen in the current frame.</span> </p>
<p><span data-start="353.11" data-end="354.94">And then the app has to immediately start</span> <span data-start="354.94" data-end="358.12">thinking about preparing for that next frame.</span> <span data-start="358.12" data-end="360.52">And the third type of work here is idle work,</span> <span data-start="360.52" data-end="363.19">which might be left over in the current frame</span> <span data-start="363.19" data-end="365.32">or there might be plenty of idle time</span> <span data-start="365.32" data-end="369.01">if no frames are being rendered.</span> <span data-start="369.01" data-end="370.71">So this is the terminology we are using</span> <span data-start="370.71" data-end="372.39">for these three types of work.</span> <span data-start="372.39" data-end="375.75">We have user-blocking tasks for the current frame.</span> <span data-start="375.75" data-end="378.18">This is typically to provide the user</span> <span data-start="378.18" data-end="381.09">an immediate acknowledgment of what they are doing.</span> </p>
<p><span data-start="381.09" data-end="385.83">So in our example app, this might be keeping that typing</span> <span data-start="385.83" data-end="389.1">interactive in the search box, keeping those animations going</span> <span data-start="389.1" data-end="390.03">on the page.</span> <span data-start="390.03" data-end="392.16">Overall, keeping the page responsive overall — </span> <span data-start="392.16" data-end="394.11">buttons should be toggleable.</span> <span data-start="394.11" data-end="396.93">Default work is this next category of work.</span> <span data-start="396.93" data-end="398.61">This is typically user visible.</span> </p>
<p><span data-start="398.61" data-end="402.69">And this is preparing for the next frame or a future frame.</span> <span data-start="402.69" data-end="404.37">And in our example, this would be</span> <span data-start="404.37" data-end="408.77">the work of the post-processing, preparing the search results,</span> <span data-start="408.77" data-end="410.61">rendering them in time.</span> <span data-start="410.61" data-end="413.08">And finally, the third category, idle work.</span> <span data-start="413.08" data-end="416.61">This is typically work that is not user visible.</span> <span data-start="416.61" data-end="418.26">This can be at the end of the frame</span> <span data-start="418.26" data-end="420.48">or if no frames are being rendered —  things</span> <span data-start="420.48" data-end="423.54">like analytics, backups, syncs, or indexing.</span> </p>
<p><span data-start="426.63" data-end="430.99">So on the right here, we've listed some existing</span> <span data-start="430.99" data-end="434.68">primitives, existing ways how a developer might</span> <span data-start="434.68" data-end="438.07">be able to submit work to the browser to target</span> <span data-start="438.07" data-end="439.49">these priority levels.</span> <span data-start="439.49" data-end="442.37">So for user-blocking, input handler, and request</span> <span data-start="442.37" data-end="445.21">animation frames are great for this.</span> </p>
<p><span data-start="445.21" data-end="448.3">It's also worth noting that micro tasks are suited</span> <span data-start="448.3" data-end="450.43">for user-blocking urgent work.</span> <span data-start="450.43" data-end="452.92">They do not yield to the event loop.</span> <span data-start="452.92" data-end="455.59">And we've seen some bad cases where developers</span> <span data-start="455.59" data-end="458.23">are accidentally doing non-urgent or large amounts</span> <span data-start="458.23" data-end="461.68">of work without realizing it's blocking rendering.</span> <span data-start="461.68" data-end="463.78">The second thing, default. We have</span> <span data-start="463.78" data-end="466.24">things like setTimeout zero, postMessage.</span> <span data-start="466.24" data-end="468.34">These are really hacks and work arounds.</span> <span data-start="468.34" data-end="470.89">There isn't a real primitive here.</span> <span data-start="470.89" data-end="472.87">And we are working to fill this gap.</span> </p>
<p><span data-start="472.87" data-end="475.78">And finally, for idle, requestIdleCallback</span> <span data-start="475.78" data-end="477.58">is a great API.</span> <span data-start="477.58" data-end="481.84">So JavaScript schedulers can be built today</span> <span data-start="481.84" data-end="483.78">using these primitives.</span> <span data-start="483.78" data-end="486.13">Now while it's possible to build a scheduling</span> <span data-start="486.13" data-end="490.21">system in JavaScript, they suffer from gaps</span> <span data-start="490.21" data-end="496.31">primarily because they don't have enough control on signals</span> <span data-start="496.31" data-end="498.37">to properly control scheduling.</span> <span data-start="498.37" data-end="501.56">So we'll go through some examples.</span> </p>
<p><span data-start="501.56" data-end="503.92">So for example, we've seen JavaScript schedulers</span> <span data-start="503.92" data-end="506.744">are trying to estimate the frame deadline.</span> <span data-start="506.744" data-end="508.66">So they're doing a whole bunch of bookkeeping,</span> <span data-start="508.66" data-end="509.77">trying to guess at it.</span> <span data-start="509.77" data-end="511.811">But they're doing it poorly because it's just not</span> <span data-start="511.811" data-end="515.26">possible to do this well without knowing browser internals.</span> </p>
<p><span data-start="515.26" data-end="519">So we are considering exposing an API for that.</span> <span data-start="519" data-end="523.24">isInputPending is a really useful signal for schedulers,</span> <span data-start="523.24" data-end="526.27">and we are actively exploring an API.</span> <span data-start="526.27" data-end="528.49">Then there's other coordination work.</span> <span data-start="528.49" data-end="532.78">So for example, handling fetch response priorities</span> <span data-start="532.78" data-end="534.76">is pretty relevant.</span> <span data-start="534.76" data-end="537.19">If you're doing urgent work for the current frame,</span> <span data-start="537.19" data-end="540.64">you don't want your low priority fetch responses</span> <span data-start="540.64" data-end="542.86">to come in and interrupt that.</span> </p>
<p><span data-start="542.86" data-end="545.98">In practice, though, there's a lot of other work</span> <span data-start="545.98" data-end="547.85">that's happening in the browser.</span> <span data-start="547.85" data-end="550.27">The browser might initiate various callbacks</span> <span data-start="550.27" data-end="552.82">such as ready state change for XHR</span> <span data-start="552.82" data-end="555.22">or a postMessage might come in from a worker.</span> <span data-start="555.22" data-end="557.44">There's internal work like [INAUDIBLE]..</span> <span data-start="557.44" data-end="560.77">And it's just not possible to codify priorities</span> <span data-start="560.77" data-end="564.35">for all of this and [INAUDIBLE] signals.</span> </p>
<p><span data-start="564.35" data-end="568.84">So this got us thinking, how about moving the scheduler one</span> <span data-start="568.84" data-end="572.77">level down and integrating it directly with the browser's</span> <span data-start="572.77" data-end="576.55">event loop where we already have most of these signals</span> <span data-start="576.55" data-end="578.62">and a lot of great information?</span> <span data-start="578.62" data-end="581.32">And this would solve an additional problem.</span> </p>
<p><span data-start="581.32" data-end="583.3">That is this coordination problem</span> <span data-start="583.3" data-end="585.92">between multiple parties in the app.</span> <span data-start="585.92" data-end="589.54">If you have third party content, or embedded libraries or legacy</span> <span data-start="589.54" data-end="593.29">code, or even other frameworks, they can all co-exist and use</span> <span data-start="593.29" data-end="598.93">the same day scheduling system with consistent priorities.</span> <span data-start="598.93" data-end="604.11">So this is a very early sketch of what an API might look like.</span> <span data-start="604.11" data-end="608.52">The key thing here is a set of global task use targeting</span> <span data-start="608.52" data-end="609.73">each priority level.</span> <span data-start="609.73" data-end="611.76">And so this is really simple and straightforward</span> <span data-start="611.76" data-end="615.54">compared to using a myriad different APIs.</span> <span data-start="615.54" data-end="617.16">The second thing is we think it will</span> <span data-start="617.16" data-end="620.85">be useful to have a notion of user-defined task</span> <span data-start="620.85" data-end="622.47">queues, a virtual task queues.</span> </p>
<p><span data-start="622.47" data-end="625.38">And this would give developers more control</span> <span data-start="625.38" data-end="630.45">over managing a group of tasks and doing bulk operations</span> <span data-start="630.45" data-end="633.6">like updating priority, canceling all the tasks,</span> <span data-start="633.6" data-end="637.44">or flushing the task used if the app is going away.</span> </p>
</section>

<section>
<p><span data-start="637.44" data-end="640.077"><span class="speaker">Jason Miller</span>: Right, so here we can see a simplified</span> <span data-start="640.077" data-end="641.91">version of that map scheduler that we looked</span> <span data-start="641.91" data-end="644.7">at using this task queue API.</span> <span data-start="644.7" data-end="648.47">So first, we hook into the user blocking and default task</span> <span data-start="648.47" data-end="651.61">queues just to give ourselves a high and a low priority queue.</span> <span data-start="651.61" data-end="653.94">And then we start listening for pointermoves events.</span> </p>
<p><span data-start="653.94" data-end="655.815">And each time we receive one of these events,</span> <span data-start="655.815" data-end="658.44">we enqueue a pan task with coordinates</span> <span data-start="658.44" data-end="660.06">at that pointermove.</span> <span data-start="660.06" data-end="662.61">The pan task translates the map tiles, obviously.</span> </p>
<p><span data-start="662.61" data-end="666.09">And then it might, let's say, enqueue a low priority task</span> <span data-start="666.09" data-end="670.11">to detect any tiles that have moved into the viewport</span> <span data-start="670.11" data-end="672.36">and potentially load those tiles.</span> <span data-start="672.36" data-end="675.78">The thing to note here is if we receive a new pointermove event</span> <span data-start="675.78" data-end="679.29">before we've invoked this loadMoreTiles task, that</span> <span data-start="679.29" data-end="681.87">would be given a higher priority than loading more tiles.</span> <span data-start="681.87" data-end="683.203">And that's exactly what we want.</span> <span data-start="683.203" data-end="686.44">We give higher priority to input-driven tasks.</span> <span data-start="686.44" data-end="688.332">And let's say the team behind Maps</span> <span data-start="688.332" data-end="690.54">needed to track analytics or do something in response</span> <span data-start="690.54" data-end="692.79">to pan gestures, they'll be a good case for something</span> <span data-start="692.79" data-end="695.637">like an idle priority task.</span> </p>
<p></p>
</section>

<section>
<p><span data-start="695.637" data-end="697.97"><span class="speaker">Shubhie Panicker</span>: So here you can see most of the frames</span> <span data-start="697.97" data-end="700.47">are in green and getting rendered in time.</span> <span data-start="700.47" data-end="703.31">And this is what a well scheduled system looks like.</span> <span data-start="703.31" data-end="704.84">The work is chunked up.</span> <span data-start="704.84" data-end="707.15">There is high priority work happening</span> <span data-start="707.15" data-end="710.06">at the beginning of every frame, followed by style,</span> <span data-start="710.06" data-end="712.07">layout, paint in purple and green,</span> <span data-start="712.07" data-end="715.7">just immediately followed by default priority work in yellow</span> <span data-start="715.7" data-end="719.9">to prepare for the next frame, as well as idle priority work</span> <span data-start="719.9" data-end="721.56">being properly interleaved.</span> <span data-start="721.56" data-end="724.58">And this time is adequately utilized.</span> <span data-start="724.58" data-end="726.24">Next.</span> <span data-start="726.24" data-end="729.65">So all the APIs proposals we showed today</span> <span data-start="729.65" data-end="731.33">are super early stage.</span> </p>
<p><span data-start="731.33" data-end="734.75">We actually don't know what the end game here is going to be.</span> <span data-start="734.75" data-end="739.73">This is a really great time to give us feedback and help</span> <span data-start="739.73" data-end="742.16">us chart the course here.</span> <span data-start="742.16" data-end="743.9">For web developers, we really think</span> <span data-start="743.9" data-end="746.66">that there is an opportunity here with improved scheduling,</span> <span data-start="746.66" data-end="750.32">even if they're just properly using existing primitives.</span> <span data-start="750.32" data-end="752.18">For framework authors, we want to urge</span> <span data-start="752.18" data-end="754.79">you to consider a scheduling system</span> <span data-start="754.79" data-end="758.99">and collaborate with us now to develop the right set of APIs</span> <span data-start="758.99" data-end="760.28">in this space.</span> <span data-start="760.28" data-end="763.76">React's work on concurrent and time slicing</span> <span data-start="763.76" data-end="766.01">has proven that frameworks can really</span> <span data-start="766.01" data-end="769.34">play a good role in terms of helping apps</span> <span data-start="769.34" data-end="772.71">improve responsiveness of apps.</span> </p>
<p><span data-start="772.71" data-end="774.45">And we're already working with React</span> <span data-start="774.45" data-end="777.18">and actively looking to form partnerships</span> <span data-start="777.18" data-end="779.65">with other frameworks and apps.</span> <span data-start="779.65" data-end="781.77">This is a link to our GitHub repo.</span> <span data-start="781.77" data-end="784.41">Filing issues on the repo is a great way</span> <span data-start="784.41" data-end="786.75">to get that feedback dialogue going.</span> </p>
</section>

<section>
<p><span data-start="786.75" data-end="787.71"><span class="speaker">Jason Miller</span>: Right.</span> <span data-start="787.71" data-end="792.12">So what about work that can't be chunked, though?</span> <span data-start="792.12" data-end="795.21">What if we have a bunch of JavaScript we need to execute,</span> <span data-start="795.21" data-end="798.03">and it's really difficult or even potentially impossible</span> <span data-start="798.03" data-end="800.46">to break that work up?</span> <span data-start="800.46" data-end="802.891">Here's an example that illustrates what I mean.</span> <span data-start="802.891" data-end="804.39">Let's say we have a text editor that</span> <span data-start="804.39" data-end="806.49">does something like live JavaScript bundling</span> <span data-start="806.49" data-end="807.66">as you type.</span> <span data-start="807.66" data-end="810.63">If I load in a decent amount of code here,</span> <span data-start="810.63" data-end="812.62">things start to be a little bit slow.</span> </p>
<p><span data-start="812.62" data-end="814.08">So every time the bundling process</span> <span data-start="814.08" data-end="817.8">kicks in response to my input, it blocks the main thread.</span> <span data-start="817.8" data-end="819.69">And this causes the cursor to freeze</span> <span data-start="819.69" data-end="822.64">and it queues up my text input until bundling is completed.</span> <span data-start="822.64" data-end="824.88">And this really disrupts the typing experience.</span> <span data-start="824.88" data-end="828.48">You can see that in the CPU profile here on the right.</span> <span data-start="828.48" data-end="831.6">So it would be really difficult to break</span> <span data-start="831.6" data-end="833.58">that work up into 50 millisecond chunks,</span> <span data-start="833.58" data-end="834.76">and that's for two reasons.</span> </p>
<p><span data-start="834.76" data-end="837.99">First, I didn't write any of the Bundler code,</span> <span data-start="837.99" data-end="841.98">so modifying that would be a lot of work, particularly for me.</span> <span data-start="841.98" data-end="844.77">Plus there is a whole bunch of different libraries</span> <span data-start="844.77" data-end="847.53">that are being used to actually make these things happen,</span> <span data-start="847.53" data-end="848.4">those dependencies.</span> <span data-start="848.4" data-end="851.55">And downloading, parsing, and evaluating those dependencies</span> <span data-start="851.55" data-end="853.65">on the main thread blocks.</span> <span data-start="853.65" data-end="857.689">So using background threads lets us offload that work and get it</span> <span data-start="857.689" data-end="859.98">off the main thread so the main thread can sort of just</span> <span data-start="859.98" data-end="862.62">keep handling input.</span> <span data-start="862.62" data-end="865.02">There's a few use cases that lend themselves extremely</span> <span data-start="865.02" data-end="866.34">well to this approach.</span> <span data-start="866.34" data-end="869.19">If you're building a computer aided design tool, a game,</span> <span data-start="869.19" data-end="871.44">or doing encoding, these are great places</span> <span data-start="871.44" data-end="874.05">to just start with threads.</span> </p>
<p><span data-start="874.05" data-end="877.364">Same thing for AI, machine learning, crypto.</span> <span data-start="877.364" data-end="879.28">If these are the types of things you're doing,</span> <span data-start="879.28" data-end="881.22">you should start here.</span> <span data-start="881.22" data-end="884.652">In the browser, our primitive for threading is the worker.</span> <span data-start="884.652" data-end="886.11">So if you haven't used Workers, you</span> <span data-start="886.11" data-end="889.09">haven't used them in a while, they're basically threads.</span> <span data-start="889.09" data-end="890.715">They have a simple messaging interface,</span> <span data-start="890.715" data-end="892.53">so you can send a message to the worker,</span> <span data-start="892.53" data-end="894.33">and you can receive a message back.</span> <span data-start="894.33" data-end="897.18">They have no DOM access whatsoever and a very limited</span> <span data-start="897.18" data-end="900.709">global scope, kind of just fetch and module stuff.</span> <span data-start="900.709" data-end="902.25">And they shipped around 10 years ago,</span> <span data-start="902.25" data-end="905.53">and they're available essentially everywhere.</span> </p>
<p><span data-start="905.53" data-end="908.04">So the API for workers looks like this.</span> <span data-start="908.04" data-end="910.11">You will instantiate the worker constructor</span> <span data-start="910.11" data-end="912.26">and pass up the name of a script.</span> <span data-start="912.26" data-end="913.95">And then we can listen for messages</span> <span data-start="913.95" data-end="915.76">coming back out of that worker.</span> <span data-start="915.76" data-end="917.68">And we can send messages down to the worker.</span> <span data-start="917.68" data-end="920.32">So here, we're sending it a message that's an object.</span> <span data-start="920.32" data-end="922.725">And this describes that we would like to, say, invoke</span> <span data-start="922.725" data-end="924.81">a computeHash function.</span> <span data-start="924.81" data-end="927.3">And we're going to pass it the contents of a file,</span> <span data-start="927.3" data-end="929.41">expressed here as an array buffer.</span> </p>
<p><span data-start="929.41" data-end="931.56">The second argument to postMessage is interesting.</span> <span data-start="931.56" data-end="933.35">This tells the browser to, rather than</span> <span data-start="933.35" data-end="937.23">structured cloning the array buffer, it will transfer it in.</span> <span data-start="937.23" data-end="939.76">Finally once computeHash has completed,</span> <span data-start="939.76" data-end="942.69">it will say, postMessage back to our thread</span> <span data-start="942.69" data-end="945.727">and will be dropped into the message handler on line 3.</span> </p>
</section>

<section>
<p><span data-start="945.727" data-end="947.31"><span class="speaker">Shubhie Panicker</span>: So under the covers,</span> <span data-start="947.31" data-end="950.869">this postMessage of the data is incurring a serialization</span> <span data-start="950.869" data-end="951.66">on the main thread.</span> </p>
<p><span data-start="951.66" data-end="953.52">And it's getting queued up, hopping over</span> <span data-start="953.52" data-end="956.46">to a worker thread, followed by deserialization.</span> <span data-start="956.46" data-end="959.46">And end-to-end, this is called a thread hop.</span> <span data-start="959.46" data-end="962.37">And this thread hop has a cost, and primarily</span> <span data-start="962.37" data-end="964.47">from the data being subject to what</span> <span data-start="964.47" data-end="966.09">is called structured cloning, which</span> <span data-start="966.09" data-end="969.06">is a copying behavior while recursing the JavaScript</span> <span data-start="969.06" data-end="969.84">object.</span> <span data-start="969.84" data-end="976.27">The size of the data is relevant to the cost of the thread hop.</span> <span data-start="976.27" data-end="979.45">So one downside of the postMessage API</span> <span data-start="979.45" data-end="982.12">is that it doesn't have a notion of statefulness</span> <span data-start="982.12" data-end="983.935">between the request and the response.</span> </p>
<p><span data-start="983.935" data-end="986.29">So if you make a whole bunch of requests,</span> <span data-start="986.29" data-end="988.21">you'll get a whole bunch of responses back.</span> <span data-start="988.21" data-end="992.077">And it's hard to correlate those responses to requests.</span> </p>
</section>

<section>
<p><span data-start="992.077" data-end="992.91"><span class="speaker">Jason Miller</span>: Right.</span> <span data-start="992.91" data-end="995.076">So we've seen how to communicate with a worker using</span> <span data-start="995.076" data-end="995.97">postMessage.</span> <span data-start="995.97" data-end="998.19">There's actually a number of ways you can do this.</span> <span data-start="998.19" data-end="1000.32">A second way would be to use MessageChannel.</span> <span data-start="1000.32" data-end="1002.32">MessageChannel is something you can instantiate,</span> <span data-start="1002.32" data-end="1003.56">and you get back two ports.</span> </p>
<p><span data-start="1003.56" data-end="1006.83">You can pass your other port to some other contexts like a tab</span> <span data-start="1006.83" data-end="1010.55">or a frame or a worker, and you can message between the two.</span> <span data-start="1010.55" data-end="1013.37">They have the same interface, as we just saw.</span> <span data-start="1013.37" data-end="1015.26">Another one would be BroadcastChannel.</span> <span data-start="1015.26" data-end="1017.09">This is like a MessageChannel that's</span> <span data-start="1017.09" data-end="1019.16">shared to all contexts associated</span> <span data-start="1019.16" data-end="1021.44">with an origin, so all tabs, frames, workers,</span> <span data-start="1021.44" data-end="1022.52">service worker.</span> <span data-start="1022.52" data-end="1024.74">And all you do is you instantiate a BroadcastChannel</span> <span data-start="1024.74" data-end="1026.579">with a channel keyword.</span> <span data-start="1026.579" data-end="1029.06">And you message without having to pass ports around.</span> <span data-start="1029.06" data-end="1030.976">Soon we're actually going to have a fourth way</span> <span data-start="1030.976" data-end="1031.68">to communicate.</span> </p>
<p><span data-start="1031.68" data-end="1033.14">And this is transferable streams.</span> <span data-start="1033.14" data-end="1035.597">It lends itself really well to things like audio and video</span> <span data-start="1035.597" data-end="1038.18">where the format you would want to use to express these things</span> <span data-start="1038.18" data-end="1039.65">is streaming.</span> <span data-start="1039.65" data-end="1043.52">The thing with all of these APIs is that they're message-based.</span> <span data-start="1043.52" data-end="1047.21">And based on some of the common usage patterns that we've seen</span> <span data-start="1047.21" data-end="1049.01">and what we've heard from developers,</span> <span data-start="1049.01" data-end="1052.82">we think there might be a case here for a higher level API.</span> <span data-start="1052.82" data-end="1056.51">So we've seen solutions to this in userland through libraries</span> <span data-start="1056.51" data-end="1060.17">like comlink, greenlet, workerize, via.js.</span> </p>
<p><span data-start="1060.17" data-end="1063.32">These all help coordinate messaging across boundaries</span> <span data-start="1063.32" data-end="1065.99">by abstracting that postMessage using something</span> <span data-start="1065.99" data-end="1067.474">called proxying.</span> </p>
</section>

<section>
<p><span data-start="1067.474" data-end="1069.14"><span class="speaker">Shubhie Panicker</span>: So messaging certainly</span> <span data-start="1069.14" data-end="1071.941">improves over a postMessage.</span> <span data-start="1071.941" data-end="1072.44">I'm sorry.</span> <span data-start="1072.44" data-end="1073.96">Proxying improves over postMessage,</span> <span data-start="1073.96" data-end="1075.95">but it comes with a number of downsides.</span> <span data-start="1075.95" data-end="1078.39">Every method call to a proxied object</span> <span data-start="1078.39" data-end="1082.28">incurs the cost of a thread hop, and this can come as a surprise</span> <span data-start="1082.28" data-end="1083.63">to developers.</span> <span data-start="1083.63" data-end="1088.07">Platform gaps can cause memory leaks in these APIs.</span> <span data-start="1088.07" data-end="1092.27">These APIs don't really have a notion of a backing threadpool</span> <span data-start="1092.27" data-end="1095.48">or a concept of managing threads and resizing the pool.</span> <span data-start="1095.48" data-end="1099.53">Embedded libraries are not able to share the same thread</span> <span data-start="1099.53" data-end="1100.69">or threadpool.</span> </p>
<p><span data-start="1100.69" data-end="1104.63">And for complex APIs, it can be impractical to recreate</span> <span data-start="1104.63" data-end="1108.63">this API surface cross thread.</span> <span data-start="1108.63" data-end="1110.7">So this raises the question, is there</span> <span data-start="1110.7" data-end="1114">an opportunity here for better integration with the browser?</span> <span data-start="1114" data-end="1117.62">Is there an opportunity to provide a more compelling API?</span> </p>
</section>

<section>
<p><span data-start="1117.62" data-end="1119.054"><span class="speaker">Jason Miller</span>: Right.</span> <span data-start="1119.054" data-end="1121.47">We think there might be a use case here for something that</span> <span data-start="1121.47" data-end="1123.37">looks something like this.</span> </p>
<p><span data-start="1123.37" data-end="1125.79">So here, we're passing the name of a function</span> <span data-start="1125.79" data-end="1127.92">in some other context and some arguments</span> <span data-start="1127.92" data-end="1130.8">to a theoretical postTask method.</span> <span data-start="1130.8" data-end="1133.17">This postTask method would return a promise</span> <span data-start="1133.17" data-end="1135.93">that eventually resolves to the return value of that function</span> <span data-start="1135.93" data-end="1137.69">somewhere else.</span> </p>
<p><span data-start="1137.69" data-end="1142.62">This abstract code helps us move from a message passing model</span> <span data-start="1142.62" data-end="1144.51">to a more task-oriented model.</span> </p>
</section>

<section>
<p><span data-start="1146.826" data-end="1148.95"><span class="speaker">Shubhie Panicker</span>: So in looking at the requirements</span> <span data-start="1148.95" data-end="1153.09">for a better API, we considered other platforms.</span> <span data-start="1153.09" data-end="1155.73">We looked at iOS and Android, which</span> <span data-start="1155.73" data-end="1159.24">have plenty of precedent for usage of background threads.</span> <span data-start="1159.24" data-end="1162.72">In particular, iOS has an API called Grand Central Dispatch,</span> <span data-start="1162.72" data-end="1164.97">which is a very stable well-proven API that's</span> <span data-start="1164.97" data-end="1167.016">loved by iOS developers.</span> <span data-start="1167.016" data-end="1169.14">Android, amongst other things, has something called</span> <span data-start="1169.14" data-end="1172.44">AsyncTask, which is a very minimal, clean API.</span> <span data-start="1172.44" data-end="1175.8">We talked to framework developers and experts</span> <span data-start="1175.8" data-end="1179.52">in usage of these APIs who were deeply familiar</span> <span data-start="1179.52" data-end="1182.56">with the pitfalls, and we learned things.</span> <span data-start="1182.56" data-end="1186.22">Some key things we learned in terms of the basic requirements</span> <span data-start="1186.22" data-end="1190.39">we want for our model is, number one, good ergonomics,</span> <span data-start="1190.39" data-end="1192.59">a way for developers to offload work</span> <span data-start="1192.59" data-end="1194.34">by just thinking in terms of submitting</span> <span data-start="1194.34" data-end="1198.13">task versus coordinating over threads.</span> </p>
<p><span data-start="1198.13" data-end="1199.87">Secondly, a native threadpool that's</span> <span data-start="1199.87" data-end="1202.99">shareable with embedded libraries and other parties</span> <span data-start="1202.99" data-end="1204.05">in the app.</span> <span data-start="1204.05" data-end="1206.86">And finally, a system-controlled thread management,</span> <span data-start="1206.86" data-end="1210.16">where the system can be in control of making decisions</span> <span data-start="1210.16" data-end="1213.59">on resizing the threadpool or decisions on where to run which</span> <span data-start="1213.59" data-end="1214.09">tasks.</span> <span data-start="1216.98" data-end="1219.17">So we set off on a path towards building</span> <span data-start="1219.17" data-end="1223.22">a basic task queue-based API inspired by Grand Central</span> <span data-start="1223.22" data-end="1224.48">Dispatch.</span> <span data-start="1224.48" data-end="1226.92">And a naive API might look like this.</span> <span data-start="1226.92" data-end="1230.08">Let's say you have three tasks, A, B, and C.</span> </p>
<p><span data-start="1230.08" data-end="1232.04">And let's say each one depends on the results</span> <span data-start="1232.04" data-end="1236.3">of the previous task, and we can submit these tasks</span> <span data-start="1236.3" data-end="1238.34">from the main thread over to worker threads.</span> <span data-start="1238.34" data-end="1240.62">And then we'll start getting responses back.</span> <span data-start="1240.62" data-end="1245.075">So here for three tasks, we paid the cost of six thread hops.</span> <span data-start="1248.02" data-end="1250.88">There's a few downsides here and gotchas.</span> <span data-start="1250.88" data-end="1253.79">So for one, these thread hops can be</span> <span data-start="1253.79" data-end="1255.86">expensive on lower-end devices.</span> <span data-start="1255.86" data-end="1257.6">And depending on the data size, it</span> <span data-start="1257.6" data-end="1261.87">can be up to 15 milliseconds, and this can add up.</span> </p>
<p><span data-start="1261.87" data-end="1263.66">This means that if these hops are</span> <span data-start="1263.66" data-end="1265.88">in the path of user interaction, this</span> <span data-start="1265.88" data-end="1270.02">can add up to multiple frames worth of latency now.</span> <span data-start="1270.02" data-end="1272.42">On Android, we've actually seen this in practice</span> <span data-start="1272.42" data-end="1276.08">in the real world in their usage of AsyncTask.</span> <span data-start="1276.08" data-end="1279.32">So one conclusion here is this notion</span> <span data-start="1279.32" data-end="1282.77">of default posting back results to the main thread is not</span> <span data-start="1282.77" data-end="1284.42">a good idea.</span> <span data-start="1284.42" data-end="1287.3">Besides the latency issue, it can cause congestion</span> <span data-start="1287.3" data-end="1288.86">from queue buildups.</span> <span data-start="1288.86" data-end="1291.26">And then you might remember from our earlier main thread</span> <span data-start="1291.26" data-end="1293.93">scheduling talk, we're doing all this work</span> <span data-start="1293.93" data-end="1297.86">to carefully chunk up our work and execute our high priority</span> <span data-start="1297.86" data-end="1299.4">and our default priority work.</span> </p>
<p><span data-start="1299.4" data-end="1302.99">And all these postMessages coming in at random times</span> <span data-start="1302.99" data-end="1305.31">messes with main thread scheduling.</span> <span data-start="1305.31" data-end="1308.75">A second thing to note here is that default posting,</span> <span data-start="1308.75" data-end="1312.62">even to the current thread, can be pretty bad.</span> <span data-start="1312.62" data-end="1316.62">And we saw this in Grand Central Dispatch with their dispatch</span> <span data-start="1316.62" data-end="1319.159">at current queue API.</span> </p>
</section>

<section>
<p><span data-start="1319.159" data-end="1321.2"><span class="speaker">Jason Miller</span>: So this brings us to a new proposal</span> <span data-start="1321.2" data-end="1324.11">we have that incorporates some of our learnings</span> <span data-start="1324.11" data-end="1325.85">from other platforms.</span> <span data-start="1325.85" data-end="1329.96">It lets developers avoid sending data back to the main thread.</span> </p>
<p><span data-start="1329.96" data-end="1333.83">It lets you chain tasks together without data transfer,</span> <span data-start="1333.83" data-end="1336.95">and pay the return cost only once.</span> <span data-start="1336.95" data-end="1339.29">It also minimizes thread hops using</span> <span data-start="1339.29" data-end="1341.6">a built-in sticky threadpool.</span> <span data-start="1341.6" data-end="1343.94">What we want is the experience that you see up here</span> <span data-start="1343.94" data-end="1345.431">on the right.</span> <span data-start="1345.431" data-end="1346.43">So let's dive into that.</span> </p>
<p><span data-start="1346.43" data-end="1348.687">If we revisit the Code Editor that we showed earlier,</span> <span data-start="1348.687" data-end="1350.27">the one that bundles JavaScript as you</span> <span data-start="1350.27" data-end="1353.24">type, if we do this using Task Worklet,</span> <span data-start="1353.24" data-end="1354.83">we can leverage some of these features</span> <span data-start="1354.83" data-end="1358.01">to improve performance fairly considerably.</span> <span data-start="1358.01" data-end="1360.08">Because Task Worklet avoids transferring</span> <span data-start="1360.08" data-end="1363.5">data between threads, the bundling and minifying tasks</span> <span data-start="1363.5" data-end="1365.63">in this demo can actually all reuse</span> <span data-start="1365.63" data-end="1369.23">the same AST that is generated from that initial parse task.</span> </p>
<p><span data-start="1369.23" data-end="1372.2">In the end, only the resulting minified code,</span> <span data-start="1372.2" data-end="1374.03">which is a relatively small string,</span> <span data-start="1374.03" data-end="1377.53">actually gets sent back to the main thread.</span> <span data-start="1377.53" data-end="1379.53">So the implementation looks something like this.</span> <span data-start="1379.53" data-end="1381.53">First, we create a Worklet module,</span> <span data-start="1381.53" data-end="1383.83">and that registers named task processors.</span> <span data-start="1383.83" data-end="1386.07">These are just classes with a process method.</span> <span data-start="1386.07" data-end="1387.9">Then over on the main thread, we can</span> <span data-start="1387.9" data-end="1392.73">coordinate that data flow using this postTask.</span> <span data-start="1392.73" data-end="1394.71">So we're going to parse the code and then</span> <span data-start="1394.71" data-end="1397.95">pass that resulting AST through the bundle and minify tasks.</span> <span data-start="1397.95" data-end="1399.45">And the important thing to note here</span> <span data-start="1399.45" data-end="1403.71">is that none of these variables are actually holding values.</span> <span data-start="1403.71" data-end="1407.07">These are just pointers to data that exists in the threadpool.</span> <span data-start="1407.07" data-end="1408.72">Data transfer back to the main thread</span> <span data-start="1408.72" data-end="1411.51">only happens when we await the result</span> <span data-start="1411.51" data-end="1414.87">property of that last task.</span> </p>
<p><span data-start="1414.87" data-end="1417.21">So doing this in a typical workers implementation</span> <span data-start="1417.21" data-end="1420.06">would normally take six hops, as we saw.</span> <span data-start="1420.06" data-end="1421.32">We executed three tasks.</span> <span data-start="1421.32" data-end="1424.17">We need to pass a message down and backup for each of them.</span> <span data-start="1424.17" data-end="1426.96">In Task Worklet, this is only two thread</span> <span data-start="1426.96" data-end="1430.8">hops because we can transfer data between tasks.</span> <span data-start="1430.8" data-end="1433.39">Task Worklet is also backed by a threadpool.</span> <span data-start="1433.39" data-end="1436.05">So let's say we start off with a task that</span> <span data-start="1436.05" data-end="1438.1">produces a large set of images.</span> </p>
<p><span data-start="1438.1" data-end="1442.59">When we post a task with some of those images as its argument,</span> <span data-start="1442.59" data-end="1444.42">it will attempt to run in the thread</span> <span data-start="1444.42" data-end="1446.82">where that data is already available.</span> <span data-start="1446.82" data-end="1449.37">So data is never transferred between threads in this case,</span> <span data-start="1449.37" data-end="1451.5">and at least a few are thread hops.</span> <span data-start="1451.5" data-end="1453.09">To take advantage of pooling, though,</span> <span data-start="1453.09" data-end="1455.25">if there's no optimal thread available,</span> <span data-start="1455.25" data-end="1458.13">we will resort to transferring data between threads</span> <span data-start="1458.13" data-end="1460.89">in order to get parallelization.</span> <span data-start="1460.89" data-end="1462.475">And then finally, let's say the result</span> <span data-start="1462.475" data-end="1464.1">that we're looking for here is actually</span> <span data-start="1464.1" data-end="1465.87">just a comparison of the number of cats</span> <span data-start="1465.87" data-end="1468">versus the number of dog photos, since that's</span> <span data-start="1468" data-end="1470.52">what's important in the end.</span> </p>
<p><span data-start="1470.52" data-end="1472.23">In this case, the only thing we ever</span> <span data-start="1472.23" data-end="1475.2">transfer back to the main thread is a single integer.</span> <span data-start="1475.2" data-end="1477.925">And as you can imagine, that's extremely cheap.</span> <span data-start="1477.925" data-end="1479.55">So we've been thinking a lot about what</span> <span data-start="1479.55" data-end="1482.01">the future of web development off the main thread</span> <span data-start="1482.01" data-end="1485.1">might look like today we have libraries like Comlink that</span> <span data-start="1485.1" data-end="1487.47">use reflection to kind of emulate</span> <span data-start="1487.47" data-end="1489.39">the interface of some code running in a worker</span> <span data-start="1489.39" data-end="1491.848">so that it could be called from the main thread seamlessly.</span> <span data-start="1491.848" data-end="1495.21">In the future, we think we might move towards a Task Worklet</span> <span data-start="1495.21" data-end="1498.75">model where developers approach multi-threaded web programming</span> <span data-start="1498.75" data-end="1499.89">in sort of a different way.</span> <span data-start="1499.89" data-end="1502.98">You have a threadpool that's managed automatically, named</span> <span data-start="1502.98" data-end="1505.92">tasks, and this concept of a task graph</span> <span data-start="1505.92" data-end="1510.43">that optimizes execution and data flow.</span> </p>
<p><span data-start="1510.43" data-end="1512.962">So this is a really early proposal.</span> <span data-start="1512.962" data-end="1514.92">We are looking for feedback, and we are looking</span> <span data-start="1514.92" data-end="1516.79">for real-world use cases.</span> <span data-start="1516.79" data-end="1518.82">There is an implementation available in Chromium</span> <span data-start="1518.82" data-end="1522.32">behind the Experimental Web Platform Features flag.</span> <span data-start="1522.32" data-end="1524.58">And also we have Polyfill and some source code</span> <span data-start="1524.58" data-end="1527.39">and demos available at this GitHub repo.</span> <span data-start="1527.39" data-end="1530.105">There will be a link at the end of the presentation as well.</span> </p>
</section>

<section>
<p><span data-start="1530.105" data-end="1531.48"><span class="speaker">Shubhie Panicker</span>: So there's been</span> <span data-start="1531.48" data-end="1535.14">a lot of interest in this idea of multi-threaded JavaScript</span> <span data-start="1535.14" data-end="1536.62">over the last couple years.</span> <span data-start="1536.62" data-end="1538.62">There have been several independent explorations</span> <span data-start="1538.62" data-end="1540.6">by various frameworks and apps.</span> <span data-start="1540.6" data-end="1543.09">So we dug into this in the last few months</span> <span data-start="1543.09" data-end="1546.51">to understand how far can we get with just using the worker</span> <span data-start="1546.51" data-end="1550.17">API as a way to achieve threadedness.</span> </p>
<p><span data-start="1550.17" data-end="1553.86">And to set some context here, a new worker</span> <span data-start="1553.86" data-end="1556.5">doesn't just spin up a raw OS thread.</span> <span data-start="1556.5" data-end="1559.38">It actually creates its own JavaScript environment</span> <span data-start="1559.38" data-end="1561.65">on top of this.</span> <span data-start="1561.65" data-end="1564.54">And part of that is what's called a V8 isolate, which</span> <span data-start="1564.54" data-end="1567.27">has a non-trivial weight in addition</span> <span data-start="1567.27" data-end="1569.13">to the weight of the OS thread.</span> <span data-start="1569.13" data-end="1572.76">A key implication here is that the worker,</span> <span data-start="1572.76" data-end="1575.19">by creating its own JavaScript environment,</span> <span data-start="1575.19" data-end="1578.55">is not able to share data or code with the main thread.</span> </p>
<p><span data-start="1578.55" data-end="1581.16">And this is fundamentally different from background</span> <span data-start="1581.16" data-end="1586.56">threads on other platforms and other languages.</span> <span data-start="1586.56" data-end="1590.48">So this has implications in terms of using Workers</span> <span data-start="1590.48" data-end="1592.32">in a mainstream way.</span> <span data-start="1592.32" data-end="1595.58">And by that I mean when the worker is in the path of user</span> <span data-start="1595.58" data-end="1596.6">interaction.</span> </p>
<p><span data-start="1596.6" data-end="1599.54">In particular, we looked at two app development models</span> <span data-start="1599.54" data-end="1600.8">using worker.</span> <span data-start="1600.8" data-end="1603.85">The first one is doing state management in a worker,</span> <span data-start="1603.85" data-end="1606.68">and this is where you can do the heavy lifting, business</span> <span data-start="1606.68" data-end="1608.48">logic-y stuff in a worker.</span> <span data-start="1608.48" data-end="1611.96">And the second model goes even further</span> <span data-start="1611.96" data-end="1614.57">and does the bulk of rendering in the worker.</span> <span data-start="1614.57" data-end="1617.81">Now while worker doesn't have access to the DOM,</span> <span data-start="1617.81" data-end="1620">there are libraries like WorkerDOM.</span> <span data-start="1620" data-end="1622.95">So you can do virtual DOM updates in the worker</span> <span data-start="1622.95" data-end="1626.25">and then ferry the [? diffs ?] back to the main thread.</span> <span data-start="1626.25" data-end="1630.47">So real apps have been built using these models.</span> <span data-start="1630.47" data-end="1633.23">However, there are some significant challenges</span> <span data-start="1633.23" data-end="1635.99">that we want to highlight here if you're</span> <span data-start="1635.99" data-end="1638.57">planning to go down this route.</span> </p>
<p><span data-start="1638.57" data-end="1644.54">The first thing is that it's hard to have synchronous access</span> <span data-start="1644.54" data-end="1647.69">to a worker, but real apps need synchronous access</span> <span data-start="1647.69" data-end="1648.812">to their app state.</span> <span data-start="1648.812" data-end="1650.27">So what this means is sometimes you</span> <span data-start="1650.27" data-end="1652.353">want to look up your app state on the main thread,</span> <span data-start="1652.353" data-end="1655.57">and sometimes you might update that app state on a worker.</span> <span data-start="1655.57" data-end="1658.88">And this means you now have to maintain and replicate</span> <span data-start="1658.88" data-end="1662.39">this app state in both places and synchronize it</span> <span data-start="1662.39" data-end="1663.63">continuously.</span> <span data-start="1663.63" data-end="1667.64">And this has a cost in terms of thread hops.</span> <span data-start="1667.64" data-end="1670.91">The second thing here is that the worker has to be</span> <span data-start="1670.91" data-end="1674.42">bootstrapped with all the script and modules that it needs</span> <span data-start="1674.42" data-end="1677.3">because, like we said, it cannot share code with the main</span> <span data-start="1677.3" data-end="1677.96">thread.</span> </p>
<p><span data-start="1677.96" data-end="1682.63">And this has implications for startup delay.</span> <span data-start="1682.63" data-end="1687.46">So we run benchmarks to dig into this base cost of a worker.</span> <span data-start="1687.46" data-end="1690.79">And these are some numbers from a medium Android device.</span> <span data-start="1690.79" data-end="1693.25">Startup takes upwards of 10 millisecond.</span> </p>
<p><span data-start="1693.25" data-end="1696.05">And this is, again, a Chrome on Android.</span> <span data-start="1696.05" data-end="1700.24">A thread hop varies anywhere from one to 15 milliseconds,</span> <span data-start="1700.24" data-end="1705.42">depending on the device and the size and type of the data.</span> <span data-start="1705.42" data-end="1707.89">Look out for a blog post that will</span> <span data-start="1707.89" data-end="1711.25">be accompanying this talk in the next week or two.</span> <span data-start="1711.25" data-end="1713.59">And we will have some detailed links to our benchmarks</span> <span data-start="1713.59" data-end="1715.82">and data there.</span> <span data-start="1715.82" data-end="1719.33">We also set up more realistic benchmarks.</span> </p>
<p><span data-start="1719.33" data-end="1721.22">We built apps that were representing</span> <span data-start="1721.22" data-end="1723.8">the app development models we mentioned, that is,</span> <span data-start="1723.8" data-end="1727.49">the state management in a worker and rendering in a worker.</span> <span data-start="1727.49" data-end="1731.94">And we did a ton of runs on real mobile devices,</span> <span data-start="1731.94" data-end="1733.76">both with and without worker.</span> </p>
<p><span data-start="1733.76" data-end="1736.16">And we looked at a variety of metrics,</span> <span data-start="1736.16" data-end="1739.61">everything from loading metrics, memory metrics,</span> <span data-start="1739.61" data-end="1743.99">to rendering metrics, such as frame rate and input latency.</span> <span data-start="1743.99" data-end="1747.6">And we approximated input latency using cycle time.</span> <span data-start="1747.6" data-end="1751.73">So again, the blog post will have more details on this.</span> </p>
<p><span data-start="1751.73" data-end="1756.13">But I do want to highlight one bit of interesting data.</span> <span data-start="1756.13" data-end="1759.96">So this is basically showing runs</span> <span data-start="1759.96" data-end="1762.75">with an app that is representative</span> <span data-start="1762.75" data-end="1764.19">of rendering in a worker.</span> <span data-start="1764.19" data-end="1768.63">The red are runs with worker, and blue runs without worker.</span> <span data-start="1768.63" data-end="1772.14">So what we are seeing here is that on worker, we</span> <span data-start="1772.14" data-end="1775.65">are seeing a higher and more improved frame rate.</span> <span data-start="1775.65" data-end="1777.72">But on the flip side, we are also</span> <span data-start="1777.72" data-end="1781.2">seeing a higher input latency.</span> <span data-start="1781.2" data-end="1783.15">So there is a fundamental trade-off</span> <span data-start="1783.15" data-end="1789.06">here between improved smoothness versus user latency.</span> </p>
<p><span data-start="1789.06" data-end="1792.88">Workers are able to free up the main thread by offloading work.</span> <span data-start="1792.88" data-end="1794.85">And so they can free up that main thread</span> <span data-start="1794.85" data-end="1800.07">to focus on rendering, and less grip means fewer long task</span> <span data-start="1800.07" data-end="1801.9">hiccups on the main thread.</span> <span data-start="1801.9" data-end="1804.78">Again, on the flip side, input latency</span> <span data-start="1804.78" data-end="1807">suffers from thread hops.</span> <span data-start="1807" data-end="1809.73">And the worker environment is a limited environment</span> <span data-start="1809.73" data-end="1810.87">and doesn't have APIs.</span> <span data-start="1810.87" data-end="1812.28">And it's not just the DOM.</span> <span data-start="1812.28" data-end="1814.93">There are many other APIs as that are still not available,</span> <span data-start="1814.93" data-end="1816.45">like media, audio, et cetera.</span> </p>
</section>

<section>
<p><span data-start="1816.45" data-end="1817.26"><span class="speaker">Jason Miller</span>: Yeah.</span> </p>
<p><span data-start="1817.26" data-end="1818.94">So the key thing to take away from this</span> <span data-start="1818.94" data-end="1823.26">is, workers might be able to make your rendering smoother,</span> <span data-start="1823.26" data-end="1826.29">but they might do it at the expense of a bit of input</span> <span data-start="1826.29" data-end="1827.67">delay.</span> <span data-start="1827.67" data-end="1830.4">There's cases, though, where this is completely worth it.</span> <span data-start="1830.4" data-end="1831.91">So AMPscript is a great example.</span> <span data-start="1831.91" data-end="1834.03">AMPscript renders using workers in order</span> <span data-start="1834.03" data-end="1837.33">to sandbox, potentially misbehaving JavaScript.</span> <span data-start="1837.33" data-end="1839.49">Slower or problematic code that's</span> <span data-start="1839.49" data-end="1842.34">running in the worker in this emulated DOM</span> <span data-start="1842.34" data-end="1845.792">can't negatively impact the AMP document.</span> </p>
<p><span data-start="1845.792" data-end="1847.5">And so for AMP, the benefits they get out</span> <span data-start="1847.5" data-end="1850.92">of sandboxing untrusted code far outweigh the latency</span> <span data-start="1850.92" data-end="1853.89">that they get from transferring events.</span> <span data-start="1853.89" data-end="1857.04">So we wanted to summarize when they use workers,</span> <span data-start="1857.04" data-end="1860.92">but it turns out there's no perfect rubric for this.</span> <span data-start="1860.92" data-end="1863.34">So there's a couple of hints you can use though.</span> <span data-start="1863.34" data-end="1865.53">If you have code that blocks for a long time,</span> <span data-start="1865.53" data-end="1867.81">if you have code with small inputs and outputs,</span> <span data-start="1867.81" data-end="1870.88">or something that follows the simple request response model,</span> <span data-start="1870.88" data-end="1873.91">you might be in a position to start off with workers.</span> <span data-start="1873.91" data-end="1876.36">However, if you have code that relies on the DOM</span> <span data-start="1876.36" data-end="1879.09">or is directly in the path of input response,</span> <span data-start="1879.09" data-end="1882">or just code that needs really minimal overhead,</span> <span data-start="1882" data-end="1884.25">you might want to start off with a different solution.</span> </p>
<p><span data-start="1884.25" data-end="1886.77">You could approach workers later.</span> <span data-start="1886.77" data-end="1889.5">When adopting a threaded approach to state management,</span> <span data-start="1889.5" data-end="1892.2">make sure that your state management and business</span> <span data-start="1892.2" data-end="1895.62">logic outweighs the cost of creating a worker</span> <span data-start="1895.62" data-end="1897.27">and sending and receiving messages.</span> <span data-start="1897.27" data-end="1901.009">Make sure that your worker is pulling its own weight.</span> </p>
<p><span data-start="1901.009" data-end="1902.55">So we're at the beginning of a fairly</span> <span data-start="1902.55" data-end="1907.14">major shift in how applications are developed for the web.</span> <span data-start="1907.14" data-end="1910.08">We're excited to explore new possibilities</span> <span data-start="1910.08" data-end="1912.67">for effective scheduling and threading.</span> <span data-start="1912.67" data-end="1914.719">And we hope that all of you are too.</span> </p>
</section>

<section>
<p><span data-start="1914.719" data-end="1916.26"><span class="speaker">Shubhie Panicker</span>: And so we just want</span> <span data-start="1916.26" data-end="1918.69">to leave you with some of these key messages from our talk</span> <span data-start="1918.69" data-end="1919.53">today.</span> <span data-start="1919.53" data-end="1921.72">It's hard to achieve responsiveness guarantees</span> <span data-start="1921.72" data-end="1924.21">because there's so much work happening in modern apps.</span> <span data-start="1924.21" data-end="1926.4">And we think scheduling is a compelling strategy</span> <span data-start="1926.4" data-end="1927.63">for tackling this.</span> <span data-start="1927.63" data-end="1930.18">There's an opportunity here for improved scheduling</span> <span data-start="1930.18" data-end="1933.57">with existing primitives as well as new primitives.</span> </p>
<p><span data-start="1933.57" data-end="1935.58">And frameworks are in a good position</span> <span data-start="1935.58" data-end="1937.29">to play a big role here.</span> <span data-start="1937.29" data-end="1940.62">In terms of offloading work from the main thread,</span> <span data-start="1940.62" data-end="1942.93">you can think of using worker as an extension</span> <span data-start="1942.93" data-end="1945.3">to better main thread scheduling.</span> <span data-start="1945.3" data-end="1948.49">Some types of work are better suited to worker than others.</span> <span data-start="1948.49" data-end="1952.02">And we think new APIs like Task Worklet</span> <span data-start="1952.02" data-end="1957.06">are going to be compelling to utilize worker for scheduling.</span> <span data-start="1957.06" data-end="1959.12">So that's about it.</span> <span data-start="1959.12" data-end="1961.95">We'll have a blog post coming with more details.</span> </p>
<p><span data-start="1961.95" data-end="1965.45">These are, again, the links to the GitHub repos.</span> <span data-start="1965.45" data-end="1969.19">Issues on the repos are very welcome and appreciated</span> <span data-start="1969.19" data-end="1972.05">and a great way too for the feedback loop.</span> <span data-start="1972.05" data-end="1976.07">And do not hesitate to reach out to us on email or Twitter.</span> <span data-start="1976.07" data-end="1976.58">Thank you.</span> <span data-start="1976.58" data-end="1979.63">[MUSIC PLAYING]</span> </p>
</section>